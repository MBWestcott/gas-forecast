{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "94d228fc",
      "metadata": {
        "id": "94d228fc"
      },
      "source": [
        "## UK natural gas system price prediction\n",
        "\n",
        "The purpose of this project is to investigate how well machine learning can predict a commodity price, given just a few market fundamentals, and previous prices, as features. I have chosen the UK natural gas market because the key data on supply, demand and prices are freely available and up to date via https://data.nationalgas.com/\n",
        "\n",
        "The goal is to predict the next day's daily System Average Price and System Marginal (Buy and Sell) Prices. The System Average Price is the volume weighted average price of trades on the UK natural gas On-the-Day Commodity Market - i.e. gas for immediate delivery. The System Marginal Price (Buy) is related to the day's highest price, and is the price that suppliers must pay for the balance of gas used by their customers, if that is more than the amount they have supplied to the system (a \"short imbalance\") The System Marginal Price (Sell) is related to the day's lowest price. The System Marginal Price (Sell) is related to the day's lowest price, and is the price that suppliers receive for any surplus gas that they have supplied to the system, which their customers have not used (a \"long imbalance\"). All prices are in pence per kilowatt-hour (p/kWh).\n",
        "\n",
        "The dataset is drawn from the five year history available at https://data.nationalgas.com/, focusing on the fields that make up the Daily Summary Report, with the data for the three target prices coming from the Prices section of the same data portal.\n",
        "\n",
        "Model performance will be measured based on Root Mean Squared Error (RMSE), as compared to the RMSE of a naive predictor that simply assumes that the next day's price will be the same as the current day's price. RMSE has been chosen as most suitable to price prediction because it penalises larger errors more harshly than smaller ones."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2bbfe169",
      "metadata": {
        "id": "2bbfe169"
      },
      "source": [
        "### Initial setup steps\n",
        "\n",
        "First we'll make sure the required libraries are available"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "9c3764d3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9c3764d3",
        "outputId": "04abeccc-667c-4ea0-fac6-d63f424aecfd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting scikit-optimize\n",
            "  Downloading scikit_optimize-0.10.2-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.4.2)\n",
            "Collecting pyaml>=16.9 (from scikit-optimize)\n",
            "  Downloading pyaml-25.1.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.14.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (1.6.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from scikit-optimize) (24.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.0->scikit-optimize) (3.6.0)\n",
            "Downloading scikit_optimize-0.10.2-py2.py3-none-any.whl (107 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.8/107.8 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyaml-25.1.0-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: pyaml, scikit-optimize\n",
            "Successfully installed pyaml-25.1.0 scikit-optimize-0.10.2\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import datetime\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "!pip install scikit-optimize # needed on Google Colab\n",
        "from skopt import BayesSearchCV\n",
        "from skopt.space import Real, Integer\n",
        "\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "557a2bba",
      "metadata": {
        "id": "557a2bba"
      },
      "source": [
        "Initial steps if running on Google Colab, to download support files from GitHub and set the working directory. This includes the data from nationalgas.com in csv format, and also \"PUB ids.txt\" which is the list of data item IDs to download from nationalgas.com to refresh with the latest data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "vsukzbcUFNAQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsukzbcUFNAQ",
        "outputId": "ed39c3f4-83eb-4023-90fb-27ad0b275de3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'gas-forecast'...\n",
            "remote: Enumerating objects: 189, done.\u001b[K\n",
            "remote: Counting objects: 100% (189/189), done.\u001b[K\n",
            "remote: Compressing objects: 100% (158/158), done.\u001b[K\n",
            "remote: Total 189 (delta 52), reused 150 (delta 26), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (189/189), 3.47 MiB | 4.44 MiB/s, done.\n",
            "Resolving deltas: 100% (52/52), done.\n",
            "/content/gas-forecast/notebooks\n"
          ]
        }
      ],
      "source": [
        "#for running on Colab\n",
        "!git clone https://github.com/MBWestcott/gas-forecast.git\n",
        "\n",
        "# 2. Change into the repo directory\n",
        "%cd /content/gas-forecast/notebooks\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a4cfcb1",
      "metadata": {
        "id": "8a4cfcb1"
      },
      "source": [
        "### Get the data\n",
        "Download in csv format from nationalgas.com if not already present locally"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "69f4bd0f",
      "metadata": {
        "id": "69f4bd0f"
      },
      "outputs": [],
      "source": [
        "raw_data_folder = Path(\"../data/raw/\")\n",
        "\n",
        "def download_csv(url, output_file):\n",
        "    \"\"\"\n",
        "    Downloads a CSV file from the given URL and saves it to the specified file.\n",
        "\n",
        "    :param url: URL to download the CSV data from.\n",
        "    :param output_file: Path to the local file where the CSV will be saved.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Send a GET request to the URL\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()  # Ensure we notice bad responses\n",
        "\n",
        "        # Write the content (CSV data) to a file in binary mode\n",
        "        with open(output_file, 'wb') as f:\n",
        "            f.write(response.content)\n",
        "\n",
        "        print(f\"CSV file has been successfully downloaded and saved as '{output_file}'.\")\n",
        "\n",
        "    except requests.HTTPError as http_err:\n",
        "        print(f\"HTTP error occurred: {http_err}\")\n",
        "    except Exception as err:\n",
        "        print(f\"An error occurred: {err}\")\n",
        "\n",
        "\n",
        "def download_raw_data():\n",
        "    pubIdsFile = Path(\"../PUB ids.txt\")\n",
        "    with open(pubIdsFile) as f:\n",
        "        pubIds = f.read()\n",
        "        pubIds = pubIds.replace(\"\\n\", \",\").strip()\n",
        "\n",
        "    download_from = datetime.date.today().replace(day=1) # start first download on first day of current month\n",
        "    download_to = datetime.date.today() # end first download on today's date\n",
        "    earliest = download_from.replace(year = download_from.year - 5) # Download data going back 5 years\n",
        "    while(download_from > earliest):\n",
        "\n",
        "        # Format the date in yyyy-mm-dd format for the download URL\n",
        "        formatted_from = download_from.strftime(\"%Y-%m-%d\")\n",
        "        formatted_to = download_to.strftime(\"%Y-%m-%d\")\n",
        "\n",
        "        csv_url = f\"https://data.nationalgas.com/api/find-gas-data-download?applicableFor=Y&dateFrom={formatted_from}&dateTo={formatted_to}&dateType=GASDAY&latestFlag=Y&ids={pubIds}&type=CSV\"\n",
        "        month_format = download_from.strftime(\"%Y-%m\")\n",
        "        output_filename = raw_data_folder /  f\"{month_format}.csv\"\n",
        "\n",
        "        download_csv(csv_url, output_filename)\n",
        "        time.sleep(2) # brief courtesy sleep\n",
        "        download_to = download_from - datetime.timedelta(days=1) # next download should go up to the day before the previous download start date\n",
        "        download_from = download_to.replace(day=1) # next download should start on the first day of the month\n",
        "\n",
        "# Do the download if the raw data is not there already\n",
        "csvCount = sum(1 for f in raw_data_folder.iterdir() if f.is_file() and f.suffix == '.csv')\n",
        "if(csvCount < 60):\n",
        "    download_raw_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2a322d6",
      "metadata": {
        "id": "b2a322d6"
      },
      "source": [
        "### Load the data\n",
        "\n",
        "Load the raw CSVs into a single dataframe, and pivot it so that each column represents a feature.\n",
        "Rename the Applicable At date field to Gas Day, and rename the three price columns that are going to be reused for ground truth and time series"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "dd682eab",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dd682eab",
        "outputId": "d862d496-24c3-4d28-81a5-4ede2d0699cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed 10 of 60 raw files\n",
            "Processed 20 of 60 raw files\n",
            "Processed 30 of 60 raw files\n",
            "Processed 40 of 60 raw files\n",
            "Processed 50 of 60 raw files\n",
            "Processed 60 of 60 raw files\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 1819 entries, 0 to 30\n",
            "Data columns (total 45 columns):\n",
            " #   Column                                                    Non-Null Count  Dtype         \n",
            "---  ------                                                    --------------  -----         \n",
            " 0   Gas Day                                                   1819 non-null   datetime64[ns]\n",
            " 1   Aggregate LNG Importations - Daily Flow                   1816 non-null   float64       \n",
            " 2   Beach Including Norway - Daily Flow                       1816 non-null   float64       \n",
            " 3   Beach and IOG - Beach Delivery                            1815 non-null   float64       \n",
            " 4   Beach and IOG - Daily Flow                                1816 non-null   float64       \n",
            " 5   Composite Weather Variable - Actual                       1554 non-null   float64       \n",
            " 6   Composite Weather Variable - Cold                         1818 non-null   float64       \n",
            " 7   Composite Weather Variable - Normal                       1818 non-null   float64       \n",
            " 8   Composite Weather Variable - Warm                         1817 non-null   float64       \n",
            " 9   Demand - Cold                                             1817 non-null   float64       \n",
            " 10  Demand - Cold, (excluding interconnector and storage)     1817 non-null   float64       \n",
            " 11  Demand - Warm                                             1817 non-null   float64       \n",
            " 12  Demand - Warm, (excluding interconnector and storage)     1817 non-null   float64       \n",
            " 13  Demand Actual, NTS, D+1                                   1817 non-null   float64       \n",
            " 14  Demand Forecast, NTS, hourly update                       1819 non-null   float64       \n",
            " 15  Demand, NTS, SND                                          1817 non-null   float64       \n",
            " 16  Demand, NTS, SND, (excluding interconnector and storage)  1817 non-null   float64       \n",
            " 17  Interconnector - Daily Flow                               1812 non-null   float64       \n",
            " 18  Interconnector - Delivery                                 1812 non-null   float64       \n",
            " 19  LNG Stock Level                                           1818 non-null   float64       \n",
            " 20  Long Storage - Actual Stock                               1817 non-null   float64       \n",
            " 21  Long Storage - Stock Level at Max Flow                    1819 non-null   float64       \n",
            " 22  Medium Storage - Actual Stock                             1817 non-null   float64       \n",
            " 23  Medium Storage - Stock Level at Max Flow                  1819 non-null   float64       \n",
            " 24  Predicted Closing Linepack (PCLP1)                        1819 non-null   float64       \n",
            " 25  SAP, 30 day rolling average                               1816 non-null   float64       \n",
            " 26  SAP, 7 Day rolling average                                1816 non-null   float64       \n",
            " 27  SAP                                                       1816 non-null   float64       \n",
            " 28  SMPBuy                                                    1816 non-null   float64       \n",
            " 29  SMPSell                                                   1816 non-null   float64       \n",
            " 30  Short Storage - Actual Stock                              1817 non-null   float64       \n",
            " 31  Short Storage - Stock Level at Max Flow                   1819 non-null   float64       \n",
            " 32  Storage - Daily Flow                                      1816 non-null   float64       \n",
            " 33  Storage - Delivery                                        1815 non-null   float64       \n",
            " 34  Storage, Long Range, Average flow (7 days)                1817 non-null   float64       \n",
            " 35  Storage, Long Range, Maximum potential flow               1817 non-null   float64       \n",
            " 36  Storage, Long Range, Stock Levels                         1817 non-null   float64       \n",
            " 37  Storage, Medium Range, Average flow (7 days)              1817 non-null   float64       \n",
            " 38  Storage, Medium Range, Maximum potential flow             1817 non-null   float64       \n",
            " 39  Storage, Medium Range, Stock Levels                       1817 non-null   float64       \n",
            " 40  Storage, Short Range, Average flow (7 days)               1817 non-null   float64       \n",
            " 41  Storage, Short Range, Maximum potential flow              1817 non-null   float64       \n",
            " 42  Storage, Short Range, Stock Levels                        1817 non-null   float64       \n",
            " 43  System Entry Flows, National, Forecast                    1819 non-null   float64       \n",
            " 44  System Entry Flows, National, Physical                    1819 non-null   float64       \n",
            "dtypes: datetime64[ns](1), float64(44)\n",
            "memory usage: 653.7 KB\n"
          ]
        }
      ],
      "source": [
        "price_targets = [\"SAP\", \"SMPBuy\", \"SMPSell\"]\n",
        "\n",
        "def pivot(df : pd.DataFrame, cols):\n",
        "\n",
        "    #only keep the values we are interested in\n",
        "    mask = df[\"Data Item\"].isin(cols)\n",
        "\n",
        "    df_filtered = df[mask]\n",
        "\n",
        "    # if there are duplicates for the field and gas day, take the latest\n",
        "    df_latest = (\n",
        "        df_filtered\n",
        "        .sort_values(\"Applicable At\")\n",
        "        .groupby([\"Gas Day\", \"Data Item\"])\n",
        "        .last()  # this takes the row with the highest (i.e. latest) \"Applicable At\" per group\n",
        "        .reset_index()\n",
        "    )\n",
        "\n",
        "    # pivot to get 1 row per gas day\n",
        "    df_latest = df_latest.pivot(index=\"Gas Day\", columns=\"Data Item\", values=\"Value\").reset_index()\n",
        "\n",
        "    df_latest = df_latest.sort_values(\"Gas Day\", ascending=True)\n",
        "\n",
        "    return df_latest\n",
        "\n",
        "def load_data():\n",
        "    #Read raw CSVs\n",
        "    pathlist = list(Path(raw_data_folder).rglob('*.csv'))\n",
        "    file_count = len(pathlist)\n",
        "    dfs = []\n",
        "    files_done = 0\n",
        "    for path_obj in pathlist:\n",
        "        path = str(path_obj)\n",
        "\n",
        "        df = pd.read_csv(path,\n",
        "            parse_dates=[\"Applicable At\", \"Applicable For\", \"Generated Time\"],\n",
        "            dayfirst=True)\n",
        "\n",
        "        df.rename(columns={'Applicable For': 'Gas Day'}, inplace=True)\n",
        "        df['Gas Day'] = pd.to_datetime(df['Gas Day'], dayfirst=True)\n",
        "        # pivot to 1 row per gas day, with features as columns\n",
        "\n",
        "        daily_cols = df[\"Data Item\"].unique()\n",
        "\n",
        "        df_daily = pivot(df, daily_cols)\n",
        "        dfs.append(df_daily)\n",
        "\n",
        "        files_done += 1\n",
        "        if files_done % 10 == 0:\n",
        "            print(f\"Processed {files_done} of {file_count} raw files\")\n",
        "\n",
        "    df = pd.concat(dfs)\n",
        "\n",
        "    #Rename the columns that are going to be reused for ground truth and time series\n",
        "    df.rename(columns={\"SAP, Actual Day\": 'SAP', \"SMP Buy, Actual Day\": 'SMPBuy', \"SMP Sell, Actual Day\": 'SMPSell'}, inplace=True)\n",
        "    return df\n",
        "\n",
        "df = load_data()\n",
        "df.to_csv(Path(\"../data/processed/pivoted.csv\"), index=False)\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52c8e618",
      "metadata": {
        "id": "52c8e618"
      },
      "source": [
        "### Preprocess data\n",
        "\n",
        "Add the previous 5 days' prices as lag features, and 7- and 30-day rolling averages and standard deviations. Also add day of week features, and a cyclical coding of the day of year for seasonality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "267c8bfe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "id": "267c8bfe",
        "outputId": "e06550d9-6db9-4e12-e3aa-da7403fac877"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-bd75bfd3-b6cb-4cee-a6e2-274aad9a8682\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Data Item</th>\n",
              "      <th>Gas Day</th>\n",
              "      <th>Aggregate LNG Importations - Daily Flow</th>\n",
              "      <th>Beach Including Norway - Daily Flow</th>\n",
              "      <th>Beach and IOG - Beach Delivery</th>\n",
              "      <th>Beach and IOG - Daily Flow</th>\n",
              "      <th>Composite Weather Variable - Actual</th>\n",
              "      <th>Composite Weather Variable - Cold</th>\n",
              "      <th>Composite Weather Variable - Normal</th>\n",
              "      <th>Composite Weather Variable - Warm</th>\n",
              "      <th>Demand - Cold</th>\n",
              "      <th>...</th>\n",
              "      <th>SMPSell D30 roll std</th>\n",
              "      <th>Day of Week</th>\n",
              "      <th>Is Weekday</th>\n",
              "      <th>Next Day Is Weekday</th>\n",
              "      <th>Day of Year</th>\n",
              "      <th>sin_DoY</th>\n",
              "      <th>cos_DoY</th>\n",
              "      <th>Next Day SAP</th>\n",
              "      <th>Next Day SMPBuy</th>\n",
              "      <th>Next Day SMPSell</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2022-03-01</td>\n",
              "      <td>73.58762</td>\n",
              "      <td>202.91057</td>\n",
              "      <td>274.23389</td>\n",
              "      <td>274.23389</td>\n",
              "      <td>5.72234</td>\n",
              "      <td>0.38</td>\n",
              "      <td>5.34</td>\n",
              "      <td>8.99</td>\n",
              "      <td>372.013750</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>60</td>\n",
              "      <td>0.858764</td>\n",
              "      <td>0.512371</td>\n",
              "      <td>12.4195</td>\n",
              "      <td>12.8194</td>\n",
              "      <td>12.3759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2022-03-02</td>\n",
              "      <td>65.26304</td>\n",
              "      <td>201.90467</td>\n",
              "      <td>264.92421</td>\n",
              "      <td>264.92421</td>\n",
              "      <td>5.19050</td>\n",
              "      <td>0.43</td>\n",
              "      <td>5.41</td>\n",
              "      <td>9.01</td>\n",
              "      <td>369.989695</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>61</td>\n",
              "      <td>0.867456</td>\n",
              "      <td>0.497513</td>\n",
              "      <td>13.1209</td>\n",
              "      <td>13.1645</td>\n",
              "      <td>12.4543</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2022-03-03</td>\n",
              "      <td>70.25762</td>\n",
              "      <td>199.51260</td>\n",
              "      <td>267.52362</td>\n",
              "      <td>267.52362</td>\n",
              "      <td>6.29552</td>\n",
              "      <td>0.54</td>\n",
              "      <td>5.48</td>\n",
              "      <td>9.05</td>\n",
              "      <td>369.346311</td>\n",
              "      <td>...</td>\n",
              "      <td>2.036043</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>62</td>\n",
              "      <td>0.875892</td>\n",
              "      <td>0.482508</td>\n",
              "      <td>14.6407</td>\n",
              "      <td>14.6843</td>\n",
              "      <td>14.5971</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2022-03-04</td>\n",
              "      <td>71.58863</td>\n",
              "      <td>196.53987</td>\n",
              "      <td>266.05590</td>\n",
              "      <td>266.05590</td>\n",
              "      <td>5.66199</td>\n",
              "      <td>0.67</td>\n",
              "      <td>5.55</td>\n",
              "      <td>9.11</td>\n",
              "      <td>362.254686</td>\n",
              "      <td>...</td>\n",
              "      <td>1.685510</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>63</td>\n",
              "      <td>0.884068</td>\n",
              "      <td>0.467359</td>\n",
              "      <td>15.4378</td>\n",
              "      <td>15.4814</td>\n",
              "      <td>15.0134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2022-03-05</td>\n",
              "      <td>68.26045</td>\n",
              "      <td>197.68062</td>\n",
              "      <td>263.72837</td>\n",
              "      <td>263.85037</td>\n",
              "      <td>4.94469</td>\n",
              "      <td>0.80</td>\n",
              "      <td>5.63</td>\n",
              "      <td>9.17</td>\n",
              "      <td>332.337329</td>\n",
              "      <td>...</td>\n",
              "      <td>2.093385</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>64</td>\n",
              "      <td>0.891981</td>\n",
              "      <td>0.452072</td>\n",
              "      <td>15.5278</td>\n",
              "      <td>15.5714</td>\n",
              "      <td>15.1840</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 81 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bd75bfd3-b6cb-4cee-a6e2-274aad9a8682')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bd75bfd3-b6cb-4cee-a6e2-274aad9a8682 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bd75bfd3-b6cb-4cee-a6e2-274aad9a8682');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-5ee5bf6a-27a4-4de6-8db4-05cb5451abd8\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5ee5bf6a-27a4-4de6-8db4-05cb5451abd8')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-5ee5bf6a-27a4-4de6-8db4-05cb5451abd8 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "Data Item    Gas Day  Aggregate LNG Importations - Daily Flow  \\\n",
              "0         2022-03-01                                 73.58762   \n",
              "1         2022-03-02                                 65.26304   \n",
              "2         2022-03-03                                 70.25762   \n",
              "3         2022-03-04                                 71.58863   \n",
              "4         2022-03-05                                 68.26045   \n",
              "\n",
              "Data Item  Beach Including Norway - Daily Flow  \\\n",
              "0                                    202.91057   \n",
              "1                                    201.90467   \n",
              "2                                    199.51260   \n",
              "3                                    196.53987   \n",
              "4                                    197.68062   \n",
              "\n",
              "Data Item  Beach and IOG - Beach Delivery  Beach and IOG - Daily Flow  \\\n",
              "0                               274.23389                   274.23389   \n",
              "1                               264.92421                   264.92421   \n",
              "2                               267.52362                   267.52362   \n",
              "3                               266.05590                   266.05590   \n",
              "4                               263.72837                   263.85037   \n",
              "\n",
              "Data Item  Composite Weather Variable - Actual  \\\n",
              "0                                      5.72234   \n",
              "1                                      5.19050   \n",
              "2                                      6.29552   \n",
              "3                                      5.66199   \n",
              "4                                      4.94469   \n",
              "\n",
              "Data Item  Composite Weather Variable - Cold  \\\n",
              "0                                       0.38   \n",
              "1                                       0.43   \n",
              "2                                       0.54   \n",
              "3                                       0.67   \n",
              "4                                       0.80   \n",
              "\n",
              "Data Item  Composite Weather Variable - Normal  \\\n",
              "0                                         5.34   \n",
              "1                                         5.41   \n",
              "2                                         5.48   \n",
              "3                                         5.55   \n",
              "4                                         5.63   \n",
              "\n",
              "Data Item  Composite Weather Variable - Warm  Demand - Cold  ...  \\\n",
              "0                                       8.99     372.013750  ...   \n",
              "1                                       9.01     369.989695  ...   \n",
              "2                                       9.05     369.346311  ...   \n",
              "3                                       9.11     362.254686  ...   \n",
              "4                                       9.17     332.337329  ...   \n",
              "\n",
              "Data Item  SMPSell D30 roll std  Day of Week  Is Weekday  Next Day Is Weekday  \\\n",
              "0                           NaN            1           1                    1   \n",
              "1                           NaN            2           1                    1   \n",
              "2                      2.036043            3           1                    1   \n",
              "3                      1.685510            4           1                    0   \n",
              "4                      2.093385            5           0                    0   \n",
              "\n",
              "Data Item  Day of Year   sin_DoY   cos_DoY  Next Day SAP  Next Day SMPBuy  \\\n",
              "0                   60  0.858764  0.512371       12.4195          12.8194   \n",
              "1                   61  0.867456  0.497513       13.1209          13.1645   \n",
              "2                   62  0.875892  0.482508       14.6407          14.6843   \n",
              "3                   63  0.884068  0.467359       15.4378          15.4814   \n",
              "4                   64  0.891981  0.452072       15.5278          15.5714   \n",
              "\n",
              "Data Item  Next Day SMPSell  \n",
              "0                   12.3759  \n",
              "1                   12.4543  \n",
              "2                   14.5971  \n",
              "3                   15.0134  \n",
              "4                   15.1840  \n",
              "\n",
              "[5 rows x 81 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def preprocess(df: pd.DataFrame, add_lags=True, add_labels=True):\n",
        "\n",
        "    \"\"\"Deal with missing values, add lagged features, rolling averages and stds, Day of Week, and cyclic encoding for seasonality\"\"\"\n",
        "\n",
        "    if add_lags:\n",
        "        lag_days = 5\n",
        "        for i in range(1, lag_days+1):\n",
        "            for pt in price_targets:\n",
        "                df[f\"{pt} D-{i}\"] = df[pt].shift(i)\n",
        "\n",
        "        # add rolling averages and stds\n",
        "        for pt in price_targets:\n",
        "            for window in [7, 30]:\n",
        "                df[f'{pt} D{window} roll mean'] = (\n",
        "                    df[pt]\n",
        "                    .shift(1)               # so today's feature doesn't include today's price\n",
        "                    .rolling(window=window, min_periods=1)\n",
        "                    .mean()\n",
        "                    )\n",
        "                df[f'{pt} D{window} roll std'] = (\n",
        "                    df[pt]\n",
        "                    .shift(1)               # so today's feature doesn't include today's price\n",
        "                    .rolling(window=window, min_periods=1)\n",
        "                    .std()\n",
        "                )\n",
        "\n",
        "    # add day of week\n",
        "    df['Day of Week'] = df['Gas Day'].dt.weekday\n",
        "    df['Is Weekday'] = (df['Gas Day'].dt.weekday < 5).astype(int)\n",
        "    df['Next Day Is Weekday'] = ((df['Gas Day'] + pd.Timedelta(days=1)).dt.weekday < 5).astype(int)\n",
        "    # cyclic encoding for seasonality\n",
        "    df['Day of Year'] = df['Gas Day'].dt.dayofyear\n",
        "    df['sin_DoY'] = np.sin(2 * np.pi * df['Day of Year'] / 365)\n",
        "    df['cos_DoY'] = np.cos(2 * np.pi * df['Day of Year'] / 365)\n",
        "\n",
        "    if add_labels:\n",
        "        # Add labels for next day's actuals\n",
        "        for pt in price_targets:\n",
        "            df[f\"Next Day {pt}\"] = df[pt].shift(-1)\n",
        "\n",
        "    return df\n",
        "\n",
        "df = preprocess(df)\n",
        "df.to_csv(Path(\"../data/processed/preprocessed.csv\"), index=False)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff3358d8",
      "metadata": {
        "id": "ff3358d8"
      },
      "source": [
        "### Clean missing values and outliers\n",
        "\n",
        "Most of the missing values are missing \"Composite Weather Variable - Actual\" from 2020-21. These affect around 15% of the dataset. The best way to fill in those is with the Normal forecast, which should usually be the closest. Apart from that there are very few missing readings so it is feasible to discard any remaining rows with missing data (done at the end, to avoid introducing discrepancies into the lag features)\n",
        "\n",
        "Also remove outliers where any of the prices was 0, and one of the next day prices was more than 50% away from the current day's price"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "c9c69e5a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 620
        },
        "id": "c9c69e5a",
        "outputId": "4bc2a522-ec9e-4d96-8f50-7a1f59c56f5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1796, 78)\n",
            "(1796, 78)\n",
            "(1796, 78)\n",
            "(1749, 78)\n",
            "(1749, 78)\n",
            "(1749, 78)\n",
            "(1749, 78)\n",
            "(1743, 78)\n",
            "(1743, 78)\n",
            "(1742, 78)\n",
            "(1742, 78)\n",
            "(1723, 78)\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-3d3357c9-bd02-4655-8dac-2b1c149b9fc7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Data Item</th>\n",
              "      <th>Gas Day</th>\n",
              "      <th>Aggregate LNG Importations - Daily Flow</th>\n",
              "      <th>Beach Including Norway - Daily Flow</th>\n",
              "      <th>Beach and IOG - Beach Delivery</th>\n",
              "      <th>Beach and IOG - Daily Flow</th>\n",
              "      <th>Composite Weather Variable - Actual</th>\n",
              "      <th>Demand - Cold</th>\n",
              "      <th>Demand - Cold, (excluding interconnector and storage)</th>\n",
              "      <th>Demand - Warm</th>\n",
              "      <th>Demand - Warm, (excluding interconnector and storage)</th>\n",
              "      <th>...</th>\n",
              "      <th>SMPSell D30 roll std</th>\n",
              "      <th>Day of Week</th>\n",
              "      <th>Is Weekday</th>\n",
              "      <th>Next Day Is Weekday</th>\n",
              "      <th>Day of Year</th>\n",
              "      <th>sin_DoY</th>\n",
              "      <th>cos_DoY</th>\n",
              "      <th>Next Day SAP</th>\n",
              "      <th>Next Day SMPBuy</th>\n",
              "      <th>Next Day SMPSell</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2022-03-06</td>\n",
              "      <td>62.79920</td>\n",
              "      <td>202.46617</td>\n",
              "      <td>263.06017</td>\n",
              "      <td>263.06017</td>\n",
              "      <td>4.84297</td>\n",
              "      <td>326.145538</td>\n",
              "      <td>318.857221</td>\n",
              "      <td>203.281448</td>\n",
              "      <td>195.993131</td>\n",
              "      <td>...</td>\n",
              "      <td>2.198886</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>65</td>\n",
              "      <td>0.899631</td>\n",
              "      <td>0.436651</td>\n",
              "      <td>17.2482</td>\n",
              "      <td>17.2918</td>\n",
              "      <td>16.3783</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2022-03-07</td>\n",
              "      <td>57.20824</td>\n",
              "      <td>199.92887</td>\n",
              "      <td>254.91531</td>\n",
              "      <td>254.91531</td>\n",
              "      <td>4.05527</td>\n",
              "      <td>359.730396</td>\n",
              "      <td>352.442079</td>\n",
              "      <td>230.316954</td>\n",
              "      <td>223.028637</td>\n",
              "      <td>...</td>\n",
              "      <td>2.196663</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>66</td>\n",
              "      <td>0.907014</td>\n",
              "      <td>0.421101</td>\n",
              "      <td>17.1121</td>\n",
              "      <td>17.1557</td>\n",
              "      <td>14.3310</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2022-03-08</td>\n",
              "      <td>53.62646</td>\n",
              "      <td>192.37123</td>\n",
              "      <td>243.80549</td>\n",
              "      <td>243.80549</td>\n",
              "      <td>5.22424</td>\n",
              "      <td>357.441891</td>\n",
              "      <td>350.153573</td>\n",
              "      <td>228.996886</td>\n",
              "      <td>221.708569</td>\n",
              "      <td>...</td>\n",
              "      <td>2.340116</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>67</td>\n",
              "      <td>0.914128</td>\n",
              "      <td>0.405426</td>\n",
              "      <td>13.9936</td>\n",
              "      <td>14.0372</td>\n",
              "      <td>10.9257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2022-03-09</td>\n",
              "      <td>66.81633</td>\n",
              "      <td>183.48073</td>\n",
              "      <td>248.12036</td>\n",
              "      <td>248.48616</td>\n",
              "      <td>6.74588</td>\n",
              "      <td>355.713275</td>\n",
              "      <td>348.424958</td>\n",
              "      <td>227.588241</td>\n",
              "      <td>220.299924</td>\n",
              "      <td>...</td>\n",
              "      <td>2.180147</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>68</td>\n",
              "      <td>0.920971</td>\n",
              "      <td>0.389630</td>\n",
              "      <td>11.0825</td>\n",
              "      <td>11.1261</td>\n",
              "      <td>8.1891</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2022-03-10</td>\n",
              "      <td>41.94300</td>\n",
              "      <td>181.78669</td>\n",
              "      <td>221.57349</td>\n",
              "      <td>221.57349</td>\n",
              "      <td>8.07461</td>\n",
              "      <td>353.880518</td>\n",
              "      <td>346.592201</td>\n",
              "      <td>226.231760</td>\n",
              "      <td>218.943443</td>\n",
              "      <td>...</td>\n",
              "      <td>2.243203</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>69</td>\n",
              "      <td>0.927542</td>\n",
              "      <td>0.373720</td>\n",
              "      <td>10.5541</td>\n",
              "      <td>10.5977</td>\n",
              "      <td>9.5199</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 78 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3d3357c9-bd02-4655-8dac-2b1c149b9fc7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3d3357c9-bd02-4655-8dac-2b1c149b9fc7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3d3357c9-bd02-4655-8dac-2b1c149b9fc7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-4a9fe46f-203b-4b7e-a409-509bb01e5f7e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4a9fe46f-203b-4b7e-a409-509bb01e5f7e')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-4a9fe46f-203b-4b7e-a409-509bb01e5f7e button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "Data Item    Gas Day  Aggregate LNG Importations - Daily Flow  \\\n",
              "5         2022-03-06                                 62.79920   \n",
              "6         2022-03-07                                 57.20824   \n",
              "7         2022-03-08                                 53.62646   \n",
              "8         2022-03-09                                 66.81633   \n",
              "9         2022-03-10                                 41.94300   \n",
              "\n",
              "Data Item  Beach Including Norway - Daily Flow  \\\n",
              "5                                    202.46617   \n",
              "6                                    199.92887   \n",
              "7                                    192.37123   \n",
              "8                                    183.48073   \n",
              "9                                    181.78669   \n",
              "\n",
              "Data Item  Beach and IOG - Beach Delivery  Beach and IOG - Daily Flow  \\\n",
              "5                               263.06017                   263.06017   \n",
              "6                               254.91531                   254.91531   \n",
              "7                               243.80549                   243.80549   \n",
              "8                               248.12036                   248.48616   \n",
              "9                               221.57349                   221.57349   \n",
              "\n",
              "Data Item  Composite Weather Variable - Actual  Demand - Cold  \\\n",
              "5                                      4.84297     326.145538   \n",
              "6                                      4.05527     359.730396   \n",
              "7                                      5.22424     357.441891   \n",
              "8                                      6.74588     355.713275   \n",
              "9                                      8.07461     353.880518   \n",
              "\n",
              "Data Item  Demand - Cold, (excluding interconnector and storage)  \\\n",
              "5                                                 318.857221       \n",
              "6                                                 352.442079       \n",
              "7                                                 350.153573       \n",
              "8                                                 348.424958       \n",
              "9                                                 346.592201       \n",
              "\n",
              "Data Item  Demand - Warm  \\\n",
              "5             203.281448   \n",
              "6             230.316954   \n",
              "7             228.996886   \n",
              "8             227.588241   \n",
              "9             226.231760   \n",
              "\n",
              "Data Item  Demand - Warm, (excluding interconnector and storage)  ...  \\\n",
              "5                                                 195.993131      ...   \n",
              "6                                                 223.028637      ...   \n",
              "7                                                 221.708569      ...   \n",
              "8                                                 220.299924      ...   \n",
              "9                                                 218.943443      ...   \n",
              "\n",
              "Data Item  SMPSell D30 roll std  Day of Week  Is Weekday  Next Day Is Weekday  \\\n",
              "5                      2.198886            6           0                    1   \n",
              "6                      2.196663            0           1                    1   \n",
              "7                      2.340116            1           1                    1   \n",
              "8                      2.180147            2           1                    1   \n",
              "9                      2.243203            3           1                    1   \n",
              "\n",
              "Data Item  Day of Year   sin_DoY   cos_DoY  Next Day SAP  Next Day SMPBuy  \\\n",
              "5                   65  0.899631  0.436651       17.2482          17.2918   \n",
              "6                   66  0.907014  0.421101       17.1121          17.1557   \n",
              "7                   67  0.914128  0.405426       13.9936          14.0372   \n",
              "8                   68  0.920971  0.389630       11.0825          11.1261   \n",
              "9                   69  0.927542  0.373720       10.5541          10.5977   \n",
              "\n",
              "Data Item  Next Day SMPSell  \n",
              "5                   16.3783  \n",
              "6                   14.3310  \n",
              "7                   10.9257  \n",
              "8                    8.1891  \n",
              "9                    9.5199  \n",
              "\n",
              "[5 rows x 78 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def clean(df: pd.DataFrame, remove_outliers=True):\n",
        "    # fill missing CWV actuals with the normal forecast\n",
        "    df['Composite Weather Variable - Actual'] = df['Composite Weather Variable - Actual'].fillna(df['Composite Weather Variable - Normal'])\n",
        "\n",
        "    # There should be very remaining few rows that have any NaNs so we can drop any that do\n",
        "    df.dropna(inplace=True)\n",
        "\n",
        "    # Can drop the composite weather forecasts\n",
        "    df.drop(columns=[\"Composite Weather Variable - Normal\", \"Composite Weather Variable - Cold\", \"Composite Weather Variable - Warm\"], inplace=True)\n",
        "\n",
        "    if(remove_outliers):\n",
        "        for pt in price_targets:\n",
        "            # remove outliers where any of the prices was 0\n",
        "            print(df.shape)\n",
        "            df = df[df[pt] != 0]\n",
        "            print(df.shape)\n",
        "            df = df[df[f\"Next Day {pt}\"] != 0]\n",
        "            print(df.shape)\n",
        "            #... and where the next day price is more than 50% away from the current day's price\n",
        "            df = df[abs(df[pt] - df[f\"Next Day {pt}\"])/df[pt] < 0.5]\n",
        "            print(df.shape)\n",
        "    return df\n",
        "\n",
        "df = clean(df)\n",
        "df.to_csv(Path(\"../data/processed/preprocessed_and_cleaned.csv\"), index=False)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "821e51d3",
      "metadata": {
        "id": "821e51d3"
      },
      "source": [
        "### Split the data into training, test and validation sets\n",
        "Experimenting with two configurations:\n",
        "- Split the data sequentially by date - earliest portion to train, then later portion to validate, and the last to test. Designed to test whether the model will generalise to the most recent period, despite having been trained on earlier periods\n",
        "- Split the data randomly regardless of date\n",
        "\n",
        "Decisions will be made based on the sequential split, with results from the random split being shown alongside to help sense-check the development of the models.\n",
        "\n",
        "By default, discard data from before Q2 2021. This coincided with Covid restrictions, and experimentally this seems to improve performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "f6118dc1",
      "metadata": {
        "id": "f6118dc1"
      },
      "outputs": [],
      "source": [
        "\n",
        "def split_sequential(df, n_train = 0.7, n_validate = 0.2, n_test = 0.1, discard_before_date = '2021-04-01'):\n",
        "    \"\"\"Split based on date\"\"\"\n",
        "    df_filtered = df[df['Gas Day'] >= discard_before_date]\n",
        "    df_sorted = df_filtered.sort_values(\"Gas Day\", ascending=True)\n",
        "\n",
        "    train_df, vt_df = train_test_split(df_sorted, test_size=n_validate + n_test, train_size=n_train, shuffle=False)\n",
        "    validate_df, test_df = train_test_split(vt_df, test_size=n_test/(n_validate + n_test), train_size=n_validate/(n_validate + n_test), shuffle=False)\n",
        "\n",
        "    return train_df, validate_df, test_df\n",
        "\n",
        "def split_random(df, n_train = 0.7, n_validate = 0.2, n_test = 0.1, discard_before_date = '2021-04-01'):\n",
        "    \"\"\"Split based on number or fraction of rows\"\"\"\n",
        "\n",
        "    df_filtered = df[df['Gas Day'] >= discard_before_date]\n",
        "    # Split the DataFrame into training and testing sets\n",
        "    train_df, vt_df = train_test_split(df_filtered, test_size=n_validate + n_test, train_size=n_train, shuffle=True)\n",
        "    validate_df, test_df = train_test_split(vt_df, test_size=n_test/(n_validate + n_test), train_size=n_validate/(n_validate + n_test), shuffle=True)\n",
        "\n",
        "    return train_df, validate_df, test_df\n",
        "\n",
        "def get_X(df):\n",
        "    ys = [\"Next Day \" + col for col in price_targets]\n",
        "    df2 = df.drop(columns=ys)\n",
        "    df2.drop(columns=[\"Gas Day\"], inplace=True)\n",
        "\n",
        "    return df2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59aabed2",
      "metadata": {
        "id": "59aabed2"
      },
      "source": [
        "### Use Root Mean Squared Error as the measure of accuracy\n",
        "\n",
        "This is appropriate to price forecasting because it penalises larger inaccuracies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "9cbf2053",
      "metadata": {
        "id": "9cbf2053"
      },
      "outputs": [],
      "source": [
        "# Root mean squared error - penalises larger errors more than smaller ones\n",
        "def get_rmse(actuals, predictions):\n",
        "    rmse =  np.sqrt(np.mean((predictions - actuals)**2))\n",
        "    return round(rmse, 4)\n",
        "\n",
        "\n",
        "def print_model_stats(model, X):\n",
        "\n",
        "    # 1. Coefficients and intercept\n",
        "    if hasattr(model, \"coef_\"):\n",
        "        #print(\"Coefficients:\", model.coef_)      # array of shape (n_features,)\n",
        "        cdf = pd.DataFrame(model.coef_, X.columns, columns=['Coefficients'])\n",
        "        cdf = cdf.sort_values(by='Coefficients', ascending=False)\n",
        "        print(cdf)\n",
        "    if hasattr(model, \"intercept_\"):\n",
        "        print(\"Intercept:\", model.intercept_)    # scalar (or array if multi-output)\n",
        "\n",
        "    # 2. Model parameters\n",
        "    print(\"Parameters:\", model.get_params())\n",
        "\n",
        "    # 3. Linear algebra internals\n",
        "    if hasattr(model, \"rank_\"):\n",
        "        print(\"Rank of design matrix:\", model.rank_)\n",
        "    if hasattr(model, \"singular_\"):\n",
        "        print(\"Singular values of X:\", model.singular_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3fe56398",
      "metadata": {
        "id": "3fe56398"
      },
      "source": [
        "### Set up a framework to train models, and compare their performance on the validation dataset against a naive predictor\n",
        "\n",
        "The naive predictor takes the current day's System Average Price and System Marginal Prices as the predictions for the next day"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "8a0ec407",
      "metadata": {
        "id": "8a0ec407"
      },
      "outputs": [],
      "source": [
        "SPLIT_RANDOM = \"Random\"\n",
        "SPLIT_SEQUENTIAL = \"Sequential\"\n",
        "\n",
        "class Context:\n",
        "    \"\"\"Context for a model evaluation\"\"\"\n",
        "\n",
        "    def __init__(self, model_type, test_set):\n",
        "        self.model_type = model_type\n",
        "        self.test_set = test_set\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"Context(model_type={self.model_type}, test_set={self.test_set})\"\n",
        "\n",
        "class Result:\n",
        "    \"\"\"Result of a model evaluation\"\"\"\n",
        "\n",
        "    def __init__(self, context:Context, price_label, model_rmse, naive_rmse):\n",
        "        self.context = context\n",
        "        self.price_label = price_label\n",
        "        self.model_rmse = model_rmse\n",
        "        self.naive_rmse = naive_rmse\n",
        "        self.timestamp = datetime.datetime.now()\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"GasPredictResult(context={self.context}, price_label={self.price_label}, model_rmse={self.model_rmse}, naive_rmse={self.naive_rmse}, timestamp={self.timestamp})\"\n",
        "\n",
        "def get_y(df, col):\n",
        "    return df[\"Next Day \" + col]\n",
        "\n",
        "def validate_model(model, X, y):\n",
        "    y_pred = model.predict(X)\n",
        "    rmse = get_rmse(y, y_pred)\n",
        "    return rmse\n",
        "\n",
        "def train_and_validate_model(model, df_train, df_validate, col):\n",
        "    X_train = get_X(df_train)\n",
        "    X_validate = get_X(df_validate)\n",
        "    y_train = get_y(df_train, col)\n",
        "    y_validate = get_y(df_validate, col)\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    rmse_train = validate_model(model, X_train, y_train)\n",
        "    rmse_validate = validate_model(model, X_validate, y_validate)\n",
        "\n",
        "    return model, rmse_train, rmse_validate\n",
        "\n",
        "def train_validate_and_report_for_prices(model_factory, df_train: pd.DataFrame, df_validate: pd.DataFrame, context:Context, print_model_stats=True):\n",
        "    results = []\n",
        "    for pt in price_targets:\n",
        "        # Instantiate model.\n",
        "        model = model_factory()\n",
        "\n",
        "        # Train and validate it\n",
        "        model, rmse_train, rmse_validate = train_and_validate_model(model, df_train, df_validate, pt)\n",
        "\n",
        "        # Print model details\n",
        "        if print_model_stats:\n",
        "            X_train = get_X(df_train)\n",
        "            print_model_stats(model, X_train)\n",
        "\n",
        "        # Get naive prediction stats for comparison\n",
        "        rmse_naive_train = naive_predictions(df_train, pt)\n",
        "        rmse_naive_validate = naive_predictions(df_validate, pt)\n",
        "\n",
        "        print_results(pt + \" train\", rmse_naive_train, rmse_train)\n",
        "        print_results(pt + \" validate\", rmse_naive_validate, rmse_validate)\n",
        "\n",
        "        testResult = Result(context, pt, rmse_validate, rmse_naive_validate)\n",
        "        results.append(testResult)\n",
        "\n",
        "    return results\n",
        "\n",
        "def naive_predictions(df, priceTarget):\n",
        "    #Naive prediction uses the current day's price as its prediction for next day's price, e.g. in the dataframe, use \"SAP\" as the prediction for \"Next Day SAP\"\n",
        "    naive_predictions = df[priceTarget]\n",
        "    actuals = df[f\"Next Day {priceTarget}\"]\n",
        "    return get_rmse(actuals, naive_predictions)\n",
        "\n",
        "def print_results(case, rmse_naive, rmse_model):\n",
        "    headline = \"Worse\" if rmse_naive <= rmse_model else \"Better\"\n",
        "    print(f\"{case} - {headline} - model {rmse_model} v naive {rmse_naive}\")\n",
        "\n",
        "# List to store the results throughout the model selection process\n",
        "all_results = []"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75cb01d0",
      "metadata": {
        "id": "75cb01d0"
      },
      "source": [
        "### Try linear regression models\n",
        "\n",
        "...to predict each of SAP (System Average Price), SMPBuy (System Marginal Price - Buy) and SMPSell (System Marginal Price - Sell)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "id": "39429681",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39429681",
        "outputId": "1e8f9214-6e98-4328-dbe1-013492164138"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Linear regression model:\n",
            "Using random train-validate-test split...\n",
            "SAP train - Better - model 0.4281 v naive 0.5477\n",
            "SAP validate - Worse - model 0.3643 v naive 0.3518\n",
            "SMPBuy train - Better - model 0.506 v naive 0.6088\n",
            "SMPBuy validate - Worse - model 0.4385 v naive 0.3985\n",
            "SMPSell train - Better - model 0.5676 v naive 0.615\n",
            "SMPSell validate - Worse - model 0.5079 v naive 0.4461\n",
            "Using sequential train-validate-test split...\n",
            "SAP train - Better - model 0.4698 v naive 0.5968\n",
            "SAP validate - Worse - model 0.2416 v naive 0.128\n",
            "SMPBuy train - Better - model 0.5562 v naive 0.6659\n",
            "SMPBuy validate - Worse - model 0.3189 v naive 0.1346\n",
            "SMPSell train - Better - model 0.6703 v naive 0.7327\n",
            "SMPSell validate - Worse - model 0.3424 v naive 0.1151\n",
            "[GasPredictResult(context=Context(model_type=Linear regression, test_set=Random), price_label=SAP, model_rmse=0.3643, naive_rmse=0.3518, timestamp=2025-04-25 16:06:40.249749), GasPredictResult(context=Context(model_type=Linear regression, test_set=Random), price_label=SMPBuy, model_rmse=0.4385, naive_rmse=0.3985, timestamp=2025-04-25 16:06:40.264744), GasPredictResult(context=Context(model_type=Linear regression, test_set=Random), price_label=SMPSell, model_rmse=0.5079, naive_rmse=0.4461, timestamp=2025-04-25 16:06:40.280059), GasPredictResult(context=Context(model_type=Linear regression, test_set=Sequential), price_label=SAP, model_rmse=0.2416, naive_rmse=0.128, timestamp=2025-04-25 16:06:40.299732), GasPredictResult(context=Context(model_type=Linear regression, test_set=Sequential), price_label=SMPBuy, model_rmse=0.3189, naive_rmse=0.1346, timestamp=2025-04-25 16:06:40.315551), GasPredictResult(context=Context(model_type=Linear regression, test_set=Sequential), price_label=SMPSell, model_rmse=0.3424, naive_rmse=0.1151, timestamp=2025-04-25 16:06:40.331656)]\n"
          ]
        }
      ],
      "source": [
        "print (\"Linear regression model:\")\n",
        "model_factory = lambda: LinearRegression()\n",
        "\n",
        "print(\"Using random train-validate-test split...\")\n",
        "context = Context(\"Linear regression\", SPLIT_RANDOM)\n",
        "train, validate, test = split_random(df)\n",
        "all_results += train_validate_and_report_for_prices(model_factory, train, validate, context, print_model_stats=False)\n",
        "\n",
        "print(\"Using sequential train-validate-test split...\")\n",
        "context = Context(\"Linear regression\", SPLIT_SEQUENTIAL)\n",
        "train, validate, test = split_sequential(df)\n",
        "all_results += train_validate_and_report_for_prices(model_factory, train, validate, context, print_model_stats=False)\n",
        "\n",
        "print(all_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2dd9746",
      "metadata": {
        "id": "b2dd9746"
      },
      "source": [
        "### Try a random forest model\n",
        "Linear regression generally performed worse than the naive predictor in validation, especially using a date-based split, so let's try a random forest model. The hyperparameters were picked by a brief random search as giving the best results for the 3 price predictions overall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "id": "bc25ac1d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bc25ac1d",
        "outputId": "4867a964-4b6e-46ad-bcd3-d39719e3d01b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random forest model:\n",
            "Using random train-validate-test split...\n",
            "SAP train - Better - model 0.2035 v naive 0.4611\n",
            "SAP validate - Better - model 0.5955 v naive 0.6634\n",
            "SMPBuy train - Better - model 0.2213 v naive 0.5217\n",
            "SMPBuy validate - Better - model 0.6934 v naive 0.7192\n",
            "SMPSell train - Better - model 0.2919 v naive 0.6144\n",
            "SMPSell validate - Worse - model 0.7477 v naive 0.6734\n",
            "Using sequential train-validate-test split...\n",
            "SAP train - Better - model 0.2327 v naive 0.5968\n",
            "SAP validate - Worse - model 0.1399 v naive 0.128\n",
            "SMPBuy train - Better - model 0.2708 v naive 0.6659\n",
            "SMPBuy validate - Worse - model 0.146 v naive 0.1346\n",
            "SMPSell train - Better - model 0.3336 v naive 0.7327\n",
            "SMPSell validate - Worse - model 0.1411 v naive 0.1151\n"
          ]
        }
      ],
      "source": [
        "print (\"Random forest model:\")\n",
        "#RandomForestRegressor(n_estimators = 500, min_samples_split = 2, min_samples_leaf= 2, max_features = 0.9, max_depth = 20, ccp_alpha = 0.0) # best from random searh\n",
        "#RandomForestRegressor(n_estimators = 200, min_samples_split = 2, min_samples_leaf= 2, max_features = 0.7, max_depth = 20, ccp_alpha = 0.0) # best for SAP: SAP test - Better - model 0.77 v naive 0.8\n",
        "model_factory = lambda: RandomForestRegressor(n_estimators = 500, min_samples_split = 2, min_samples_leaf= 2, max_features = 0.9, max_depth = 20, ccp_alpha = 0.0)\n",
        "\n",
        "print(\"Using random train-validate-test split...\")\n",
        "context = Context(\"Random forest\", SPLIT_RANDOM)\n",
        "train, validate, test = split_random(df)\n",
        "all_results += train_validate_and_report_for_prices(model_factory, train, validate, context, print_model_stats=False)\n",
        "\n",
        "print(\"Using sequential train-validate-test split...\")\n",
        "context = Context(\"Random forest\", SPLIT_SEQUENTIAL)\n",
        "train, validate, test = split_sequential(df)\n",
        "all_results += train_validate_and_report_for_prices(model_factory, train, validate, context, print_model_stats=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24774087",
      "metadata": {
        "id": "24774087"
      },
      "source": [
        "### Next, try gradient boosting\n",
        "Again the random forest improves in validation over the naive predictor slightly on a random split but not when trained on earlier data and validated on later. Let's try tree-based gradient boosting using same number of estimators and max depth as the random forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "id": "0cecf345",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cecf345",
        "outputId": "7bf1ab54-71fc-48d3-df0d-8f5388964be2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gradient Boosting model (XGBoost XGBRegressor):\n",
            "Using random train-validate-test split...\n",
            "SAP train - Better - model 0.0004 v naive 0.5228\n",
            "SAP validate - Worse - model 0.5068 v naive 0.5044\n",
            "SMPBuy train - Better - model 0.0004 v naive 0.5686\n",
            "SMPBuy validate - Worse - model 0.6363 v naive 0.5689\n",
            "SMPSell train - Better - model 0.0005 v naive 0.6302\n",
            "SMPSell validate - Worse - model 0.7722 v naive 0.6121\n",
            "Using sequential train-validate-test split...\n",
            "SAP train - Better - model 0.0004 v naive 0.5968\n",
            "SAP validate - Worse - model 0.1719 v naive 0.128\n",
            "SMPBuy train - Better - model 0.0004 v naive 0.6659\n",
            "SMPBuy validate - Worse - model 0.2264 v naive 0.1346\n",
            "SMPSell train - Better - model 0.0004 v naive 0.7327\n",
            "SMPSell validate - Worse - model 0.1541 v naive 0.1151\n"
          ]
        }
      ],
      "source": [
        "print(\"Gradient Boosting model (XGBoost XGBRegressor):\")\n",
        "\n",
        "model_factory = lambda: XGBRegressor(\n",
        "        n_estimators=500,\n",
        "        max_depth=20,\n",
        "        learning_rate=0.1,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.7,\n",
        "        reg_alpha=0.0,\n",
        "        reg_lambda=1.0,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "print(\"Using random train-validate-test split...\")\n",
        "context = Context(\"Gradient boosting\", SPLIT_RANDOM)\n",
        "train, validate, test = split_random(df)\n",
        "all_results += train_validate_and_report_for_prices(model_factory, train, validate, context, print_model_stats=False)\n",
        "\n",
        "print(\"Using sequential train-validate-test split...\")\n",
        "context = Context(\"Gradient boosting\", SPLIT_SEQUENTIAL)\n",
        "train, validate, test = split_sequential(df)\n",
        "all_results += train_validate_and_report_for_prices(model_factory, train, validate, context, print_model_stats=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dab84acc",
      "metadata": {
        "id": "dab84acc"
      },
      "source": [
        "### Try Recurrent Neural Networks\n",
        "\n",
        "The gradient booster likewise did not perform any better than the naive predictor, especially when trained on the earlier data and validated on the later data. Let's try a neural net or two. For a simple time series, a Temporal Convolutional Net would be the obvious choice, but in this case we have a lot of market fundamentals to use as additional features so a RNN seems the better fit.\n",
        "\n",
        "The process for these (TensorFlow) RNNs is different from the sklearn models used above, so it will need a slightly different framework."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2834c00b",
      "metadata": {
        "id": "2834c00b"
      },
      "source": [
        "(1) Because of how the inputs need to be shaped into sequences, we'll load the data again, skipping the manually-engineered lag features and next-day labels. The sequencing process incorporates the lag features in its own way. We'll still fill in missing actual Composite Weather Variables with the normal forecast, but won't delete the few with outlying prices in case the RNN is sophisticated enough to make good use of them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "id": "44d0ce63",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 533
        },
        "id": "44d0ce63",
        "outputId": "82b20389-eafc-473c-b5f0-ba0d1b1d5df1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed 10 of 60 raw files\n",
            "Processed 20 of 60 raw files\n",
            "Processed 30 of 60 raw files\n",
            "Processed 40 of 60 raw files\n",
            "Processed 50 of 60 raw files\n",
            "Processed 60 of 60 raw files\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-79618720-2124-4038-bd70-b5e5e198a0a4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Data Item</th>\n",
              "      <th>Gas Day</th>\n",
              "      <th>Aggregate LNG Importations - Daily Flow</th>\n",
              "      <th>Beach Including Norway - Daily Flow</th>\n",
              "      <th>Beach and IOG - Beach Delivery</th>\n",
              "      <th>Beach and IOG - Daily Flow</th>\n",
              "      <th>Composite Weather Variable - Actual</th>\n",
              "      <th>Demand - Cold</th>\n",
              "      <th>Demand - Cold, (excluding interconnector and storage)</th>\n",
              "      <th>Demand - Warm</th>\n",
              "      <th>Demand - Warm, (excluding interconnector and storage)</th>\n",
              "      <th>...</th>\n",
              "      <th>Storage, Short Range, Maximum potential flow</th>\n",
              "      <th>Storage, Short Range, Stock Levels</th>\n",
              "      <th>System Entry Flows, National, Forecast</th>\n",
              "      <th>System Entry Flows, National, Physical</th>\n",
              "      <th>Day of Week</th>\n",
              "      <th>Is Weekday</th>\n",
              "      <th>Next Day Is Weekday</th>\n",
              "      <th>Day of Year</th>\n",
              "      <th>sin_DoY</th>\n",
              "      <th>cos_DoY</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>332</th>\n",
              "      <td>2021-04-01</td>\n",
              "      <td>56.64959</td>\n",
              "      <td>147.32989</td>\n",
              "      <td>202.42128</td>\n",
              "      <td>202.42128</td>\n",
              "      <td>8.04000</td>\n",
              "      <td>305.628045</td>\n",
              "      <td>299.428045</td>\n",
              "      <td>192.178205</td>\n",
              "      <td>185.978205</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>216.581800</td>\n",
              "      <td>235.986349</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>91</td>\n",
              "      <td>0.999991</td>\n",
              "      <td>0.004304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>333</th>\n",
              "      <td>2021-04-02</td>\n",
              "      <td>56.98982</td>\n",
              "      <td>166.66129</td>\n",
              "      <td>222.13281</td>\n",
              "      <td>222.13281</td>\n",
              "      <td>8.42962</td>\n",
              "      <td>294.933461</td>\n",
              "      <td>288.293461</td>\n",
              "      <td>184.176358</td>\n",
              "      <td>177.536358</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>226.122795</td>\n",
              "      <td>221.070202</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>92</td>\n",
              "      <td>0.999917</td>\n",
              "      <td>-0.012910</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>334</th>\n",
              "      <td>2021-04-03</td>\n",
              "      <td>59.86041</td>\n",
              "      <td>163.58733</td>\n",
              "      <td>221.85874</td>\n",
              "      <td>221.85874</td>\n",
              "      <td>7.78921</td>\n",
              "      <td>282.792862</td>\n",
              "      <td>275.712862</td>\n",
              "      <td>171.236588</td>\n",
              "      <td>164.156588</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>232.033606</td>\n",
              "      <td>249.997365</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93</td>\n",
              "      <td>0.999546</td>\n",
              "      <td>-0.030120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>335</th>\n",
              "      <td>2021-04-04</td>\n",
              "      <td>56.81811</td>\n",
              "      <td>162.65719</td>\n",
              "      <td>217.84170</td>\n",
              "      <td>217.84170</td>\n",
              "      <td>8.09275</td>\n",
              "      <td>280.273502</td>\n",
              "      <td>272.753502</td>\n",
              "      <td>168.677337</td>\n",
              "      <td>161.157337</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>219.171588</td>\n",
              "      <td>210.539110</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>94</td>\n",
              "      <td>0.998880</td>\n",
              "      <td>-0.047321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>336</th>\n",
              "      <td>2021-04-05</td>\n",
              "      <td>58.17918</td>\n",
              "      <td>155.78494</td>\n",
              "      <td>212.49572</td>\n",
              "      <td>212.49572</td>\n",
              "      <td>6.20191</td>\n",
              "      <td>297.694091</td>\n",
              "      <td>289.734091</td>\n",
              "      <td>185.852197</td>\n",
              "      <td>177.892197</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>221.809610</td>\n",
              "      <td>212.792903</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>95</td>\n",
              "      <td>0.997917</td>\n",
              "      <td>-0.064508</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 48 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-79618720-2124-4038-bd70-b5e5e198a0a4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-79618720-2124-4038-bd70-b5e5e198a0a4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-79618720-2124-4038-bd70-b5e5e198a0a4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7f966e9a-fa05-4902-903a-5ed058b34997\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7f966e9a-fa05-4902-903a-5ed058b34997')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7f966e9a-fa05-4902-903a-5ed058b34997 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "Data Item    Gas Day  Aggregate LNG Importations - Daily Flow  \\\n",
              "332       2021-04-01                                 56.64959   \n",
              "333       2021-04-02                                 56.98982   \n",
              "334       2021-04-03                                 59.86041   \n",
              "335       2021-04-04                                 56.81811   \n",
              "336       2021-04-05                                 58.17918   \n",
              "\n",
              "Data Item  Beach Including Norway - Daily Flow  \\\n",
              "332                                  147.32989   \n",
              "333                                  166.66129   \n",
              "334                                  163.58733   \n",
              "335                                  162.65719   \n",
              "336                                  155.78494   \n",
              "\n",
              "Data Item  Beach and IOG - Beach Delivery  Beach and IOG - Daily Flow  \\\n",
              "332                             202.42128                   202.42128   \n",
              "333                             222.13281                   222.13281   \n",
              "334                             221.85874                   221.85874   \n",
              "335                             217.84170                   217.84170   \n",
              "336                             212.49572                   212.49572   \n",
              "\n",
              "Data Item  Composite Weather Variable - Actual  Demand - Cold  \\\n",
              "332                                    8.04000     305.628045   \n",
              "333                                    8.42962     294.933461   \n",
              "334                                    7.78921     282.792862   \n",
              "335                                    8.09275     280.273502   \n",
              "336                                    6.20191     297.694091   \n",
              "\n",
              "Data Item  Demand - Cold, (excluding interconnector and storage)  \\\n",
              "332                                               299.428045       \n",
              "333                                               288.293461       \n",
              "334                                               275.712862       \n",
              "335                                               272.753502       \n",
              "336                                               289.734091       \n",
              "\n",
              "Data Item  Demand - Warm  \\\n",
              "332           192.178205   \n",
              "333           184.176358   \n",
              "334           171.236588   \n",
              "335           168.677337   \n",
              "336           185.852197   \n",
              "\n",
              "Data Item  Demand - Warm, (excluding interconnector and storage)  ...  \\\n",
              "332                                               185.978205      ...   \n",
              "333                                               177.536358      ...   \n",
              "334                                               164.156588      ...   \n",
              "335                                               161.157337      ...   \n",
              "336                                               177.892197      ...   \n",
              "\n",
              "Data Item  Storage, Short Range, Maximum potential flow  \\\n",
              "332                                                 0.0   \n",
              "333                                                 0.0   \n",
              "334                                                 0.0   \n",
              "335                                                 0.0   \n",
              "336                                                 0.0   \n",
              "\n",
              "Data Item  Storage, Short Range, Stock Levels  \\\n",
              "332                                       0.0   \n",
              "333                                       0.0   \n",
              "334                                       0.0   \n",
              "335                                       0.0   \n",
              "336                                       0.0   \n",
              "\n",
              "Data Item  System Entry Flows, National, Forecast  \\\n",
              "332                                    216.581800   \n",
              "333                                    226.122795   \n",
              "334                                    232.033606   \n",
              "335                                    219.171588   \n",
              "336                                    221.809610   \n",
              "\n",
              "Data Item  System Entry Flows, National, Physical  Day of Week  Is Weekday  \\\n",
              "332                                    235.986349            3           1   \n",
              "333                                    221.070202            4           1   \n",
              "334                                    249.997365            5           0   \n",
              "335                                    210.539110            6           0   \n",
              "336                                    212.792903            0           1   \n",
              "\n",
              "Data Item  Next Day Is Weekday  Day of Year   sin_DoY   cos_DoY  \n",
              "332                          1           91  0.999991  0.004304  \n",
              "333                          0           92  0.999917 -0.012910  \n",
              "334                          0           93  0.999546 -0.030120  \n",
              "335                          1           94  0.998880 -0.047321  \n",
              "336                          1           95  0.997917 -0.064508  \n",
              "\n",
              "[5 rows x 48 columns]"
            ]
          },
          "execution_count": 100,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Reload with minimal preprocessing and cleaning\n",
        "df = load_data()\n",
        "df = preprocess(df, add_lags=False, add_labels=False)\n",
        "df = clean(df, remove_outliers=False)\n",
        "df = df.sort_values('Gas Day').reset_index(drop=True) # Should already be sorted, but just in case\n",
        "df = df[df['Gas Day'] >= '2021-04-01'] # discard the earliest data, as per the train/val/test split default\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42e48096",
      "metadata": {
        "id": "42e48096"
      },
      "source": [
        "(2) Make the sequences, covering 30 days of the salient features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "id": "62f199b7",
      "metadata": {
        "id": "62f199b7"
      },
      "outputs": [],
      "source": [
        "\n",
        "WINDOW_SIZE = 30\n",
        "\n",
        "feature_cols = ['Composite Weather Variable - Actual', 'Demand Actual, NTS, D+1', 'Demand Forecast, NTS, hourly update', 'Interconnector - Daily Flow', 'Medium Storage - Actual Stock',\n",
        "              'Medium Storage - Stock Level at Max Flow', 'Predicted Closing Linepack (PCLP1)',\n",
        "              'SAP', 'SMPBuy',\t'SMPSell',\n",
        "              'Storage - Daily Flow','Storage - Delivery', 'Storage, Medium Range, Stock Levels', 'System Entry Flows, National, Forecast', 'System Entry Flows, National, Physical',\n",
        "              'Day of Week','Is Weekday','Next Day Is Weekday','Day of Year']\n",
        "\n",
        "def make_sequences(df, feature_cols):\n",
        "    X, Y = [], []\n",
        "    for i in range(len(df) - WINDOW_SIZE):\n",
        "        X.append(df[feature_cols].iloc[i : i + WINDOW_SIZE].values)\n",
        "        Y.append(df[price_targets].iloc[i + WINDOW_SIZE].values) # using SAP, SMPBuy and SMPSell as labels as before\n",
        "    return np.array(X), np.array(Y)\n",
        "\n",
        "X, y = make_sequences(df, feature_cols)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a5b5e0e",
      "metadata": {
        "id": "2a5b5e0e"
      },
      "source": [
        "(3) Split the sequences into training, validate and test sets, so that the new gas days introduced at each stage are later than the days already seen. Then scale the sets individually.\n",
        "\n",
        "Still using 70% training, 20% validation and holding back 10% for testing the finally selected model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "id": "0659b02a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0659b02a",
        "outputId": "bcf46c47-dcd0-4a87-e5fd-9e91b9a4ff6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training records: 1012\n",
            "Validation records: 289\n"
          ]
        }
      ],
      "source": [
        "train_size = int(0.7 * len(X))\n",
        "val_size   = int(0.2 * len(X))\n",
        "\n",
        "X_train, y_train = X[:train_size], y[:train_size]\n",
        "X_validate,   y_validate   = X[train_size:train_size+val_size], y[train_size:train_size+val_size]\n",
        "\n",
        "print(f\"Training records: {X_train.shape[0]}\")\n",
        "print(f\"Validation records: {X_validate.shape[0]}\")\n",
        "\n",
        "n_feats = X_train.shape[2]\n",
        "scaler = StandardScaler()\n",
        "X_train_2d = X_train.reshape(-1, n_feats)\n",
        "scaler.fit(X_train_2d)\n",
        "\n",
        "def scale_split(X):\n",
        "    X_2d = X.reshape(-1, n_feats)\n",
        "    Xs = scaler.transform(X_2d)\n",
        "    return Xs.reshape(-1, WINDOW_SIZE, n_feats)\n",
        "\n",
        "#Take a copy of the unscaled test data for comparison against the naive predictor\n",
        "X_validate_unscaled = X_validate.copy()\n",
        "\n",
        "X_train = scale_split(X_train)\n",
        "X_validate   = scale_split(X_validate)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "593fa9eb",
      "metadata": {
        "id": "593fa9eb"
      },
      "source": [
        "(4) Set up the train-and-validate framework suitable for sequential RNNs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "id": "399d25d7",
      "metadata": {
        "id": "399d25d7"
      },
      "outputs": [],
      "source": [
        "def train_and_validate_rnn(model, context:Context):\n",
        "\n",
        "    callbacks = [\n",
        "        tf.keras.callbacks.EarlyStopping(\n",
        "            monitor='val_loss',\n",
        "            patience=10,\n",
        "            restore_best_weights=True\n",
        "        ),\n",
        "        tf.keras.callbacks.ReduceLROnPlateau(\n",
        "            monitor='val_loss',\n",
        "            factor=0.5,\n",
        "            patience=5\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        validation_data=(X_validate, y_validate),\n",
        "        epochs=100,\n",
        "        batch_size=32,\n",
        "        callbacks=callbacks\n",
        "    )\n",
        "\n",
        "    # Show overall model RMSE across all 3 price predictions on validation set\n",
        "    eval_results = model.evaluate(X_validate, y_validate, return_dict=True)\n",
        "    model_rmse = eval_results['rmse']\n",
        "    print(f\"Overall RMSE: {model_rmse:.4f}\")\n",
        "\n",
        "    results = []\n",
        "    #Individual RMSE for each price target\n",
        "    y_pred = model.predict(X_validate)\n",
        "    for i, name in enumerate(price_targets):\n",
        "        # Get model RMSE for the price\n",
        "        rmse = get_rmse(y_validate[:,i], y_pred[:,i])\n",
        "        print(f\"{name} RMSE: {rmse:.4f}\")\n",
        "\n",
        "        # get naive predictor RMSE based on the unscaled inputs\n",
        "        feat_idx = feature_cols.index(name)\n",
        "        y_pred_naive = X_validate_unscaled[:, -1, feat_idx]\n",
        "        y_true = y_validate[:, i]\n",
        "        naive_rmse = get_rmse(y_true, y_pred_naive)\n",
        "        print(f\"{name} naive predictor RMSE: {naive_rmse:.4f}\")\n",
        "\n",
        "        # add stats to the local running list of results for this RNN\n",
        "        testResult = Result(context, name, rmse, naive_rmse)\n",
        "        results.append(testResult)\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6517c57",
      "metadata": {
        "id": "a6517c57"
      },
      "source": [
        "(5) Configure, train and validate a RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "id": "aec8afd0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aec8afd0",
        "outputId": "ccf43585-4c32-4e10-e25a-2e22d44d9681"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,656</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ multi_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm_8 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m6,656\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m528\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ multi_output (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │            \u001b[38;5;34m51\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,235</span> (28.26 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,235\u001b[0m (28.26 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,235</span> (28.26 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,235\u001b[0m (28.26 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 34.3062 - rmse: 5.8565 - val_loss: 6.9285 - val_rmse: 2.6322 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 28.2591 - rmse: 5.3132 - val_loss: 4.8614 - val_rmse: 2.2049 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 16.9900 - rmse: 4.1185 - val_loss: 1.4465 - val_rmse: 1.2027 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.0449 - rmse: 2.8269 - val_loss: 0.8592 - val_rmse: 0.9269 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.1768 - rmse: 2.0405 - val_loss: 0.3780 - val_rmse: 0.6148 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.5064 - rmse: 1.5793 - val_loss: 0.2077 - val_rmse: 0.4557 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.0627 - rmse: 1.4250 - val_loss: 0.1306 - val_rmse: 0.3614 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4564 - rmse: 1.2044 - val_loss: 0.1175 - val_rmse: 0.3428 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3126 - rmse: 1.1417 - val_loss: 0.1296 - val_rmse: 0.3600 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.9966 - rmse: 0.9972 - val_loss: 0.1059 - val_rmse: 0.3254 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.8762 - rmse: 0.9341 - val_loss: 0.1473 - val_rmse: 0.3838 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.7708 - rmse: 0.8765 - val_loss: 0.1472 - val_rmse: 0.3837 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.8331 - rmse: 0.9036 - val_loss: 0.1214 - val_rmse: 0.3484 - learning_rate: 0.0010\n",
            "Epoch 14/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5896 - rmse: 0.7654 - val_loss: 0.1267 - val_rmse: 0.3560 - learning_rate: 0.0010\n",
            "Epoch 15/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5785 - rmse: 0.7530 - val_loss: 0.1201 - val_rmse: 0.3466 - learning_rate: 0.0010\n",
            "Epoch 16/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5873 - rmse: 0.7653 - val_loss: 0.1252 - val_rmse: 0.3538 - learning_rate: 5.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6393 - rmse: 0.7964 - val_loss: 0.1167 - val_rmse: 0.3417 - learning_rate: 5.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5922 - rmse: 0.7688 - val_loss: 0.1200 - val_rmse: 0.3465 - learning_rate: 5.0000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5611 - rmse: 0.7478 - val_loss: 0.1094 - val_rmse: 0.3308 - learning_rate: 5.0000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6191 - rmse: 0.7850 - val_loss: 0.0994 - val_rmse: 0.3153 - learning_rate: 5.0000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4925 - rmse: 0.6961 - val_loss: 0.1086 - val_rmse: 0.3296 - learning_rate: 5.0000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6321 - rmse: 0.7918 - val_loss: 0.0964 - val_rmse: 0.3105 - learning_rate: 5.0000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5692 - rmse: 0.7536 - val_loss: 0.1064 - val_rmse: 0.3262 - learning_rate: 5.0000e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5272 - rmse: 0.7229 - val_loss: 0.0918 - val_rmse: 0.3029 - learning_rate: 5.0000e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5431 - rmse: 0.7361 - val_loss: 0.1016 - val_rmse: 0.3187 - learning_rate: 5.0000e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4707 - rmse: 0.6814 - val_loss: 0.0910 - val_rmse: 0.3016 - learning_rate: 5.0000e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5664 - rmse: 0.7511 - val_loss: 0.0769 - val_rmse: 0.2773 - learning_rate: 5.0000e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3817 - rmse: 0.6122 - val_loss: 0.0945 - val_rmse: 0.3074 - learning_rate: 5.0000e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5736 - rmse: 0.7530 - val_loss: 0.0829 - val_rmse: 0.2879 - learning_rate: 5.0000e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4724 - rmse: 0.6871 - val_loss: 0.0773 - val_rmse: 0.2781 - learning_rate: 5.0000e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5088 - rmse: 0.7115 - val_loss: 0.0825 - val_rmse: 0.2873 - learning_rate: 5.0000e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5051 - rmse: 0.7096 - val_loss: 0.0937 - val_rmse: 0.3062 - learning_rate: 5.0000e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4926 - rmse: 0.6982 - val_loss: 0.0852 - val_rmse: 0.2918 - learning_rate: 2.5000e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4319 - rmse: 0.6555 - val_loss: 0.0765 - val_rmse: 0.2766 - learning_rate: 2.5000e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5086 - rmse: 0.7125 - val_loss: 0.0838 - val_rmse: 0.2894 - learning_rate: 2.5000e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4409 - rmse: 0.6626 - val_loss: 0.0761 - val_rmse: 0.2758 - learning_rate: 2.5000e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4652 - rmse: 0.6814 - val_loss: 0.0843 - val_rmse: 0.2904 - learning_rate: 2.5000e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4153 - rmse: 0.6440 - val_loss: 0.0797 - val_rmse: 0.2824 - learning_rate: 2.5000e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4796 - rmse: 0.6920 - val_loss: 0.0817 - val_rmse: 0.2859 - learning_rate: 2.5000e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4428 - rmse: 0.6629 - val_loss: 0.0874 - val_rmse: 0.2956 - learning_rate: 2.5000e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4730 - rmse: 0.6861 - val_loss: 0.0794 - val_rmse: 0.2819 - learning_rate: 2.5000e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4005 - rmse: 0.6305 - val_loss: 0.0801 - val_rmse: 0.2830 - learning_rate: 1.2500e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4199 - rmse: 0.6469 - val_loss: 0.0791 - val_rmse: 0.2812 - learning_rate: 1.2500e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4825 - rmse: 0.6909 - val_loss: 0.0795 - val_rmse: 0.2820 - learning_rate: 1.2500e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4301 - rmse: 0.6554 - val_loss: 0.0776 - val_rmse: 0.2786 - learning_rate: 1.2500e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5519 - rmse: 0.7370 - val_loss: 0.0761 - val_rmse: 0.2758 - learning_rate: 1.2500e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4139 - rmse: 0.6418 - val_loss: 0.0759 - val_rmse: 0.2754 - learning_rate: 6.2500e-05\n",
            "Epoch 48/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4339 - rmse: 0.6554 - val_loss: 0.0772 - val_rmse: 0.2778 - learning_rate: 6.2500e-05\n",
            "Epoch 49/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4223 - rmse: 0.6475 - val_loss: 0.0767 - val_rmse: 0.2769 - learning_rate: 6.2500e-05\n",
            "Epoch 50/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3848 - rmse: 0.6184 - val_loss: 0.0765 - val_rmse: 0.2767 - learning_rate: 6.2500e-05\n",
            "Epoch 51/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3910 - rmse: 0.6248 - val_loss: 0.0772 - val_rmse: 0.2778 - learning_rate: 6.2500e-05\n",
            "Epoch 52/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5185 - rmse: 0.7184 - val_loss: 0.0763 - val_rmse: 0.2763 - learning_rate: 6.2500e-05\n",
            "Epoch 53/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4277 - rmse: 0.6529 - val_loss: 0.0772 - val_rmse: 0.2779 - learning_rate: 3.1250e-05\n",
            "Epoch 54/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3695 - rmse: 0.6070 - val_loss: 0.0760 - val_rmse: 0.2757 - learning_rate: 3.1250e-05\n",
            "Epoch 55/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4219 - rmse: 0.6491 - val_loss: 0.0763 - val_rmse: 0.2762 - learning_rate: 3.1250e-05\n",
            "Epoch 56/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4224 - rmse: 0.6488 - val_loss: 0.0763 - val_rmse: 0.2763 - learning_rate: 3.1250e-05\n",
            "Epoch 57/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4884 - rmse: 0.6955 - val_loss: 0.0766 - val_rmse: 0.2767 - learning_rate: 3.1250e-05\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1126 - rmse: 0.3307 \n",
            "Overall RMSE: 0.2754\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "SAP RMSE: 0.2942\n",
            "SAP naive predictor RMSE: 0.0723\n",
            "SMPBuy RMSE: 0.2783\n",
            "SMPBuy naive predictor RMSE: 0.0823\n",
            "SMPSell RMSE: 0.2523\n",
            "SMPSell naive predictor RMSE: 0.0736\n"
          ]
        }
      ],
      "source": [
        "def make_rnn():\n",
        "    model = models.Sequential([\n",
        "        # Single, small LSTM — no return_sequences, so it only outputs the last hidden state\n",
        "        layers.LSTM(32, input_shape=(WINDOW_SIZE, n_feats)),\n",
        "\n",
        "        # Small dense “bottleneck” to pick up any non-linear mix\n",
        "        layers.Dense(16, activation='relu'),\n",
        "\n",
        "        # Multi-output head predicts [SAP, SMPBuy, SMPSell]\n",
        "        layers.Dense(3, name='multi_output')\n",
        "    ])\n",
        "\n",
        "    # Optimise for mean squared error\n",
        "    model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "    loss='mse',\n",
        "    metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')]\n",
        "    )\n",
        "\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "\n",
        "model = make_rnn()\n",
        "context = Context(\"RNN\", SPLIT_SEQUENTIAL)\n",
        "all_results += train_and_validate_rnn(model, context)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12f23169",
      "metadata": {
        "id": "12f23169"
      },
      "source": [
        "### Finally, try reframing RNN with a residual model\n",
        "\n",
        "The RNN is still testing worse than naive predictor, indicating that the network is not learning anything from the additional fields that adds anything to the current day prices.\n",
        "As a final option, try a residual model that predicts the delta from the current day's price\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "id": "9ac9c053",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9ac9c053",
        "outputId": "bd7f2099-5a19-4e75-c8e6-8ff01767891c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_9\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_9\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_9       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,656</span> │ input_layer_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │ lstm_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ last_vals (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ delta (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │ dense_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ residual_output     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ last_vals[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │                   │            │ delta[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_9       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m19\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_9 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m6,656\u001b[0m │ input_layer_9[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │        \u001b[38;5;34m528\u001b[0m │ lstm_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ last_vals (\u001b[38;5;33mLambda\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ input_layer_9[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ delta (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │         \u001b[38;5;34m51\u001b[0m │ dense_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ residual_output     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ last_vals[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
              "│ (\u001b[38;5;33mAdd\u001b[0m)               │                   │            │ delta[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,235</span> (28.26 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,235\u001b[0m (28.26 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,235</span> (28.26 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,235\u001b[0m (28.26 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 26.4070 - rmse: 5.1377 - val_loss: 5.7919 - val_rmse: 2.4066 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 18.8394 - rmse: 4.3203 - val_loss: 2.7950 - val_rmse: 1.6718 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.1761 - rmse: 2.6707 - val_loss: 1.5635 - val_rmse: 1.2504 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.3001 - rmse: 1.5075 - val_loss: 0.8766 - val_rmse: 0.9363 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.1863 - rmse: 1.0871 - val_loss: 0.7485 - val_rmse: 0.8652 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0459 - rmse: 1.0218 - val_loss: 0.7958 - val_rmse: 0.8921 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.7538 - rmse: 0.8638 - val_loss: 0.7517 - val_rmse: 0.8670 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.8568 - rmse: 0.9239 - val_loss: 0.7206 - val_rmse: 0.8489 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6935 - rmse: 0.8288 - val_loss: 0.6824 - val_rmse: 0.8261 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6223 - rmse: 0.7879 - val_loss: 0.6710 - val_rmse: 0.8191 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6915 - rmse: 0.8300 - val_loss: 0.6860 - val_rmse: 0.8282 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6105 - rmse: 0.7799 - val_loss: 0.6450 - val_rmse: 0.8031 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5654 - rmse: 0.7510 - val_loss: 0.6892 - val_rmse: 0.8302 - learning_rate: 0.0010\n",
            "Epoch 14/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6044 - rmse: 0.7749 - val_loss: 0.6618 - val_rmse: 0.8135 - learning_rate: 0.0010\n",
            "Epoch 15/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4590 - rmse: 0.6733 - val_loss: 0.6572 - val_rmse: 0.8107 - learning_rate: 0.0010\n",
            "Epoch 16/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4546 - rmse: 0.6721 - val_loss: 0.6775 - val_rmse: 0.8231 - learning_rate: 0.0010\n",
            "Epoch 17/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5139 - rmse: 0.7141 - val_loss: 0.7228 - val_rmse: 0.8502 - learning_rate: 0.0010\n",
            "Epoch 18/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5130 - rmse: 0.7151 - val_loss: 0.7332 - val_rmse: 0.8563 - learning_rate: 5.0000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4908 - rmse: 0.6991 - val_loss: 0.7224 - val_rmse: 0.8499 - learning_rate: 5.0000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5326 - rmse: 0.7279 - val_loss: 0.7295 - val_rmse: 0.8541 - learning_rate: 5.0000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5404 - rmse: 0.7348 - val_loss: 0.7404 - val_rmse: 0.8605 - learning_rate: 5.0000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4236 - rmse: 0.6490 - val_loss: 0.7920 - val_rmse: 0.8899 - learning_rate: 5.0000e-04\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2183 - rmse: 1.0699 \n",
            "Overall RMSE: 0.8031\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "SAP RMSE: 0.6922\n",
            "SAP naive predictor RMSE: 0.0723\n",
            "SMPBuy RMSE: 0.7647\n",
            "SMPBuy naive predictor RMSE: 0.0823\n",
            "SMPSell RMSE: 0.9333\n",
            "SMPSell naive predictor RMSE: 0.0736\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def make_rnn_residual():\n",
        "    # 1) Inputs\n",
        "    inputs = layers.Input(shape=(WINDOW_SIZE, n_feats))\n",
        "\n",
        "    # 2) Core LSTM\n",
        "    x = layers.LSTM(32)(inputs)\n",
        "    x = layers.Dense(16, activation='relu')(x)\n",
        "\n",
        "    # 3) Delta prediction head (predict tomorrow’s delta for each series)\n",
        "    delta = layers.Dense(3, name='delta')(x)\n",
        "    #   outputs - [delta SAP, delta SMPBuy, delta SMPSell]\n",
        "    idxs_of_labels = [feature_cols.index(pt) for pt in price_targets]\n",
        "    # 4) Take today's values from the last timestep of the sequence\n",
        "    #    This gives shape (batch, 3) corresponding to [SAP_t, SMPBuy_t, SMPSell_t].\n",
        "    last_vals = layers.Lambda(lambda z: tf.gather(z[:, -1, :], idxs_of_labels, axis=1),\n",
        "                            name='last_vals')(inputs)\n",
        "\n",
        "    # 5) Add skip-connection: tomorrow = today + predicted delta\n",
        "    outputs = layers.Add(name='residual_output')([last_vals, delta])\n",
        "\n",
        "    model = models.Model(inputs, outputs)\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='mse',\n",
        "        metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')]\n",
        "    )\n",
        "\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "model = make_rnn_residual()\n",
        "context = Context(\"Residual RNN\", SPLIT_SEQUENTIAL)\n",
        "all_results += train_and_validate_rnn(model, context)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32ed5add",
      "metadata": {
        "id": "32ed5add"
      },
      "source": [
        "### Pick the best performing model type\n",
        "No model outperformed the naive predictor in validation so I'll have to choose the least bad one to tune based on the gathered results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "id": "192bf53f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "192bf53f",
        "outputId": "03b99301-c55f-4839-fb66-19a2c2a87d4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random forest (SMPBuy): difference over naive RMSE = -0.0114\n",
            "Random forest (SAP): difference over naive RMSE = -0.0119\n",
            "Random forest (SMPSell): difference over naive RMSE = -0.0260\n",
            "Gradient boosting (SMPSell): difference over naive RMSE = -0.0390\n",
            "Gradient boosting (SAP): difference over naive RMSE = -0.0439\n",
            "Gradient boosting (SMPBuy): difference over naive RMSE = -0.0918\n",
            "Linear regression (SAP): difference over naive RMSE = -0.1136\n",
            "RNN (SMPSell): difference over naive RMSE = -0.1787\n",
            "Linear regression (SMPBuy): difference over naive RMSE = -0.1843\n",
            "RNN (SMPBuy): difference over naive RMSE = -0.1960\n",
            "RNN (SAP): difference over naive RMSE = -0.2219\n",
            "Linear regression (SMPSell): difference over naive RMSE = -0.2273\n",
            "Residual RNN (SAP): difference over naive RMSE = -0.6199\n",
            "Residual RNN (SMPBuy): difference over naive RMSE = -0.6824\n",
            "Residual RNN (SMPSell): difference over naive RMSE = -0.8597\n"
          ]
        }
      ],
      "source": [
        "# sort by the delta (model_rmse - naive_rmse)\n",
        "#Filter results to only include \"Latest\" data test set\n",
        "filtered_results = [r for r in all_results if r.context.test_set == SPLIT_SEQUENTIAL]\n",
        "\n",
        "sorted_results = sorted(filtered_results, key=lambda r: r.naive_rmse - r.model_rmse, reverse=True)\n",
        "\n",
        "for r in sorted_results:\n",
        "    difference = r.naive_rmse - r.model_rmse\n",
        "    print(f\"{r.context.model_type} ({r.price_label}): difference over naive RMSE = {difference:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b02542e",
      "metadata": {
        "id": "8b02542e"
      },
      "source": [
        "Random forest came out best so I'll try to improve on the hyperparameters"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a45a233",
      "metadata": {
        "id": "2a45a233"
      },
      "source": [
        "### Hyperparameter search\n",
        "\n",
        "I'll use random search as a baseline and also do a bayesian search to see if that can improve further.\n",
        "\n",
        "First I'll set up a framework for the search..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "7ecec5c1",
      "metadata": {
        "id": "7ecec5c1"
      },
      "outputs": [],
      "source": [
        "# Set up search framework in order to try bayesian and random search optimization\n",
        "models_dir = Path('..') / 'models'\n",
        "\n",
        "def search_hyperparams(search, df_train, df_validate, price_target):\n",
        "    X_train = get_X(df_train)\n",
        "    y_train = get_y(df_train, price_target)\n",
        "\n",
        "    # Run the hyperparameter search\n",
        "    start = time.perf_counter()\n",
        "    search.fit(X_train, y_train)\n",
        "    end = time.perf_counter()\n",
        "\n",
        "    elapsed_minutes = (end - start) / 60\n",
        "    print(f\"Search took {elapsed_minutes:.4f} minutes\")\n",
        "\n",
        "    print(\"Best hyperparameters:\", search.best_params_)\n",
        "    print(\"Best CV RMSE on train set: {:.4f}\".format(-search.best_score_))\n",
        "\n",
        "    # Get the best model and evaluate it on the validation set\n",
        "\n",
        "    X_validate = get_X(df_validate)\n",
        "    y_validate = get_y(df_validate, price_target)\n",
        "\n",
        "    best_model = search.best_estimator_\n",
        "\n",
        "    rmse_validate = validate_model(best_model, X_validate, y_validate)\n",
        "\n",
        "    # Get naive predictor RMSE for comparison\n",
        "    rmse_naive_validate = naive_predictions(df_validate, price_target)\n",
        "\n",
        "    print_results(price_target + \" validate\", rmse_naive_validate, rmse_validate)\n",
        "    return best_model, search.best_params_, rmse_validate, rmse_naive_validate"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "NpndKffArMWe",
      "metadata": {
        "id": "NpndKffArMWe"
      },
      "source": [
        "Now to reload the data to get it back into the right format to train the sklearn RandomForestRegressor..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "6QGUjRyornId",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QGUjRyornId",
        "outputId": "72c1ce7e-7cb4-495c-ea29-152a17acfce8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed 10 of 60 raw files\n",
            "Processed 20 of 60 raw files\n",
            "Processed 30 of 60 raw files\n",
            "Processed 40 of 60 raw files\n",
            "Processed 50 of 60 raw files\n",
            "Processed 60 of 60 raw files\n",
            "(1796, 78)\n",
            "(1796, 78)\n",
            "(1796, 78)\n",
            "(1749, 78)\n",
            "(1749, 78)\n",
            "(1749, 78)\n",
            "(1749, 78)\n",
            "(1743, 78)\n",
            "(1743, 78)\n",
            "(1742, 78)\n",
            "(1742, 78)\n",
            "(1723, 78)\n"
          ]
        }
      ],
      "source": [
        "df = load_data()\n",
        "df = preprocess(df)\n",
        "df = clean(df)\n",
        "train, validate, test = split_sequential(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "SGpmYOtjruKZ",
      "metadata": {
        "id": "SGpmYOtjruKZ"
      },
      "source": [
        "Now we're ready to set up the random and Bayesian hyperparameter searches and run them for each price target. I'm aiming to allow between 45-60 minutes for the full process, which (on a Colab L4) means 50 iterations of each of the two searches for each of the three price targets. The parameter search spaces coded below have been narrowed after a couple of initial runs.\n",
        "\n",
        "Results will be reported in the output, and the best model for each price target (which might come from the random or Baysian search) will be persisted in the models folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "id": "cc5188f1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cc5188f1",
        "outputId": "3fd7bab6-97fd-4193-e68c-e79990fb9993"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SAP: Random search\n",
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "Search took 5.8126 minutes\n",
            "Best hyperparameters: {'n_estimators': 300, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 1.0, 'max_depth': 20, 'ccp_alpha': 0.005}\n",
            "Best CV RMSE on train set: 0.5555\n",
            "SAP validate - Worse - model 0.1364 v naive 0.128\n",
            "SAP: Bayesian search\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Search took 7.7670 minutes\n",
            "Best hyperparameters: OrderedDict([('ccp_alpha', 0.0033936523890966993), ('max_depth', 10), ('max_features', 1.0), ('min_samples_leaf', 1), ('min_samples_split', 3), ('n_estimators', 344)])\n",
            "Best CV RMSE on train set: 0.5500\n",
            "SAP validate - Worse - model 0.1385 v naive 0.128\n",
            "SAP: persisting model with params: {'n_estimators': 300, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 1.0, 'max_depth': 20, 'ccp_alpha': 0.005}\n",
            "SMPBuy: Random search\n",
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "Search took 5.8271 minutes\n",
            "Best hyperparameters: {'n_estimators': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 0.9, 'max_depth': 10, 'ccp_alpha': 0.005}\n",
            "Best CV RMSE on train set: 0.6348\n",
            "SMPBuy validate - Worse - model 0.1408 v naive 0.1346\n",
            "SMPBuy: Bayesian search\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Search took 8.2657 minutes\n",
            "Best hyperparameters: OrderedDict([('ccp_alpha', 0.004000634090577381), ('max_depth', 41), ('max_features', 0.9558544616340751), ('min_samples_leaf', 1), ('min_samples_split', 2), ('n_estimators', 354)])\n",
            "Best CV RMSE on train set: 0.6338\n",
            "SMPBuy validate - Worse - model 0.1415 v naive 0.1346\n",
            "SMPBuy: persisting model with params: {'n_estimators': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 0.9, 'max_depth': 10, 'ccp_alpha': 0.005}\n",
            "SMPSell: Random search\n",
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "Search took 5.9186 minutes\n",
            "Best hyperparameters: {'n_estimators': 400, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 1.0, 'max_depth': 20, 'ccp_alpha': 0.01}\n",
            "Best CV RMSE on train set: 0.7293\n",
            "SMPSell validate - Worse - model 0.1377 v naive 0.1151\n",
            "SMPSell: Bayesian search\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Search took 8.7881 minutes\n",
            "Best hyperparameters: OrderedDict([('ccp_alpha', 0.008414056270359025), ('max_depth', 10), ('max_features', 1.0), ('min_samples_leaf', 1), ('min_samples_split', 2), ('n_estimators', 423)])\n",
            "Best CV RMSE on train set: 0.7290\n",
            "SMPSell validate - Worse - model 0.136 v naive 0.1151\n",
            "SMPSell: persisting model with params: OrderedDict([('ccp_alpha', 0.008414056270359025), ('max_depth', 10), ('max_features', 1.0), ('min_samples_leaf', 1), ('min_samples_split', 2), ('n_estimators', 423)])\n",
            "Whole hyperparameter search process took 42.3909 minutes\n",
            "SMPBuy Random: difference over naive RMSE = -0.0062 with parameters: {'n_estimators': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 0.9, 'max_depth': 10, 'ccp_alpha': 0.005}\n",
            "SMPBuy Bayesian: difference over naive RMSE = -0.0069 with parameters: OrderedDict([('ccp_alpha', 0.004000634090577381), ('max_depth', 41), ('max_features', 0.9558544616340751), ('min_samples_leaf', 1), ('min_samples_split', 2), ('n_estimators', 354)])\n",
            "SAP Random: difference over naive RMSE = -0.0084 with parameters: {'n_estimators': 300, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 1.0, 'max_depth': 20, 'ccp_alpha': 0.005}\n",
            "SAP Bayesian: difference over naive RMSE = -0.0105 with parameters: OrderedDict([('ccp_alpha', 0.0033936523890966993), ('max_depth', 10), ('max_features', 1.0), ('min_samples_leaf', 1), ('min_samples_split', 3), ('n_estimators', 344)])\n",
            "SMPSell Bayesian: difference over naive RMSE = -0.0209 with parameters: OrderedDict([('ccp_alpha', 0.008414056270359025), ('max_depth', 10), ('max_features', 1.0), ('min_samples_leaf', 1), ('min_samples_split', 2), ('n_estimators', 423)])\n",
            "SMPSell Random: difference over naive RMSE = -0.0226 with parameters: {'n_estimators': 400, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 1.0, 'max_depth': 20, 'ccp_alpha': 0.01}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "# Original wide search space...\n",
        "#random_search_grid = {\n",
        "#    'n_estimators':     [100, 200, 500],\n",
        "#    'max_depth':        [None, 10, 20],\n",
        "#    'min_samples_split':[2,5],\n",
        "#    'min_samples_leaf': [1,2],\n",
        "#    'max_features':     [0.1, 0.2, 0.3, 0.4, 0.5, 0.7, 1.0],\n",
        "#    'ccp_alpha':        [0.0, 0.001]\n",
        "#}\n",
        "#... subsequently narrowed after a couple of attempts to:\n",
        "random_search_grid = {\n",
        "    'n_estimators':     [300, 400, 500],\n",
        "    'max_depth':        [None, 10, 20],\n",
        "    'min_samples_split':[2,5],\n",
        "    'min_samples_leaf': [1,2],\n",
        "    'max_features':     [0.7, 0.9, 1.0],\n",
        "    'ccp_alpha':        [0.001, 0.005, 0.01]\n",
        "}\n",
        "\n",
        "start = time.perf_counter()\n",
        "\n",
        "hyperparam_results = {}\n",
        "for pt in price_targets:\n",
        "    rf = RandomForestRegressor(\n",
        "            random_state=51,\n",
        "            n_jobs=-1,\n",
        "            oob_score=True\n",
        "        )\n",
        "    # Try random search\n",
        "    rand_search = RandomizedSearchCV(\n",
        "        estimator=rf,\n",
        "        param_distributions=random_search_grid,\n",
        "        n_iter=50,\n",
        "        cv=5,\n",
        "        scoring='neg_root_mean_squared_error',\n",
        "        n_jobs=-1,\n",
        "        verbose=3,\n",
        "        random_state=51\n",
        "    )\n",
        "\n",
        "    print(f\"{pt}: Random search\")\n",
        "    rand_best_model, rand_best_params, rand_rmse_validate, rand_rmse_naive_validate = search_hyperparams(rand_search, train, validate, pt)\n",
        "    hyperparam_results[pt + \" Random\"]= {\n",
        "        'model': rand_best_model,\n",
        "        'params': rand_best_params,\n",
        "        'model_rmse': rand_rmse_validate,\n",
        "        'naive_rmse': rand_rmse_naive_validate\n",
        "    }\n",
        "\n",
        "    # Bayesian search\n",
        "    # Original wide search space...\n",
        "    #bayes_search_spaces = {\n",
        "    #    'n_estimators':      Integer(100, 500),\n",
        "    #    'max_depth':         Integer(10, 50),\n",
        "    #    'min_samples_split': Integer(2, 5),\n",
        "    #    'min_samples_leaf':  Integer(1, 2),\n",
        "    #    'max_features':      Real(0.1, 1.0),\n",
        "    #    'ccp_alpha':         Real(0.0, 0.01)\n",
        "    #}\n",
        "    #... subsequently narrowed after a couple of attempts to:\n",
        "    bayes_search_spaces = {\n",
        "    'n_estimators':      Integer(300, 600),\n",
        "    'max_depth':         Integer(10, 50),\n",
        "    'min_samples_split': Integer(2, 5),\n",
        "    'min_samples_leaf':  Integer(1, 2),\n",
        "    'max_features':      Real(0.9, 1.0),\n",
        "    'ccp_alpha':         Real(0.0, 0.01)\n",
        "    }\n",
        "\n",
        "    rf = RandomForestRegressor(\n",
        "            random_state=51,\n",
        "            n_jobs=-1,\n",
        "            oob_score=True\n",
        "        )\n",
        "\n",
        "    bayes_search = BayesSearchCV(\n",
        "        estimator=rf,\n",
        "        search_spaces=bayes_search_spaces,\n",
        "        n_iter=50,\n",
        "        cv=5,\n",
        "        scoring='neg_root_mean_squared_error',\n",
        "        n_jobs=-1,\n",
        "        verbose=2,\n",
        "        random_state=51\n",
        "    )\n",
        "\n",
        "    print(f\"{pt}: Bayesian search\")\n",
        "    bayes_best_model, bayes_best_params, bayes_rmse_validate, bayes_rmse_naive_validate = search_hyperparams(bayes_search, train, validate, pt)\n",
        "    hyperparam_results[pt + \" Bayesian\"]= {\n",
        "        'model': bayes_best_model,\n",
        "        'params': bayes_best_params,\n",
        "        'model_rmse': bayes_rmse_validate,\n",
        "        'naive_rmse': bayes_rmse_naive_validate\n",
        "    }\n",
        "\n",
        "    # Persist the best model\n",
        "    if bayes_rmse_validate < rand_rmse_validate:\n",
        "        best_model = bayes_best_model\n",
        "        best_params = bayes_best_params\n",
        "    else:\n",
        "        best_model = rand_best_model\n",
        "        best_params = rand_best_params\n",
        "\n",
        "    print(f\"{pt}: persisting model with params: {best_params}\")\n",
        "    file_path = models_dir / f\"{pt}_best_rf.joblib\"\n",
        "    joblib.dump(best_model, file_path)\n",
        "\n",
        "\n",
        "end = time.perf_counter()\n",
        "elapsed_minutes = (end - start) / 60\n",
        "print(f\"Whole hyperparameter search process took {elapsed_minutes:.4f} minutes\")\n",
        "\n",
        "# Print out details of the best estimators from each search\n",
        "sorted_results = sorted(\n",
        "    hyperparam_results.items(),\n",
        "    key=lambda kv: kv[1]['naive_rmse'] - kv[1]['model_rmse'],\n",
        "    reverse=True\n",
        ")\n",
        "for run_name, result in sorted_results:\n",
        "    difference = result['naive_rmse'] - result['model_rmse']\n",
        "    print(f\"{run_name}: difference over naive RMSE = {difference:.4f} with parameters: {result['params']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87e76c6b",
      "metadata": {
        "id": "87e76c6b"
      },
      "source": [
        "According to the output, the best-tuned estimator for each price targets was:\n",
        "\n",
        "SMPBuy Random: difference over naive RMSE = -0.0062 with parameters: {'n_estimators': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 0.9, 'max_depth': 10, 'ccp_alpha': 0.005}\n",
        "\n",
        "\n",
        "SAP Random: difference over naive RMSE = -0.0084 with parameters: {'n_estimators': 300, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 1.0, 'max_depth': 20, 'ccp_alpha': 0.005}\n",
        "\n",
        "SMPSell Bayesian: difference over naive RMSE = -0.0209 with parameters: OrderedDict([('ccp_alpha', 0.008414056270359025), ('max_depth', 10), ('max_features', 1.0), ('min_samples_leaf', 1), ('min_samples_split', 2), ('n_estimators', 423)]).\n",
        "\n",
        "Now to reload these target and finally test against the latest 10%  of data which has been held out so far..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "4f2d4a5c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "id": "4f2d4a5c",
        "outputId": "dc73b0fc-8f8c-4cfa-9982-7b093514ef06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SAP test - Worse - model 0.2355 v naive 0.2208\n",
            "SMPBuy test - Worse - model 0.2417 v naive 0.2348\n",
            "SMPSell test - Worse - model 0.2455 v naive 0.2298\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "X_test = get_X(test)\n",
        "model_rmses = []\n",
        "naive_rmses = []\n",
        "for pt in price_targets:\n",
        "    file_path = models_dir / f\"{pt}_best_rf.joblib\"\n",
        "    model = joblib.load(file_path)\n",
        "    y_test = get_y(test, pt)\n",
        "    model_rmse = validate_model(model, X_test, y_test)\n",
        "    model_rmses.append(model_rmse)\n",
        "    naive_rmse = naive_predictions(test, pt)\n",
        "    naive_rmses.append(naive_rmse)\n",
        "    print_results(pt + \" test\", naive_rmse, model_rmse)\n",
        "\n",
        "x = range(len(price_targets))\n",
        "width = 0.35\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.bar([i - width/2 for i in x], model_rmses, width, label='Model RMSE')\n",
        "ax.bar([i + width/2 for i in x], naive_rmses, width, label='Naive predictor RMSE')\n",
        "\n",
        "ax.set_xlabel('Price Target')\n",
        "ax.set_ylabel('RMSE')\n",
        "ax.set_title('Model vs. Naive RMSE by Price Target')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(price_targets)\n",
        "ax.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "KceN_DVHZ3MX",
      "metadata": {
        "id": "KceN_DVHZ3MX"
      },
      "source": [
        "In conclusion, as often in price prediction, the naive predictor has proved to be a strong one and none of the machine learning models here has succeeded in learning anything from the fundamentals data to improve on it."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
